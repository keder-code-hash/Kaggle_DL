{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip","metadata":{"_uuid":"0d89fec7-5d44-4336-9da5-469346fa2def","_cell_guid":"b5e152ff-6613-4ecf-a299-d475fca64685","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:12:29.161715Z","iopub.execute_input":"2022-01-20T08:12:29.162009Z","iopub.status.idle":"2022-01-20T08:12:40.317184Z","shell.execute_reply.started":"2022-01-20T08:12:29.161977Z","shell.execute_reply":"2022-01-20T08:12:40.316431Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Archive:  ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\nreplace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\nreplace test_labels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\nreplace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\nreplace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers","metadata":{"_uuid":"a399aa52-641d-4b0b-ae94-428c6c4e20ff","_cell_guid":"76f4bbc5-95f6-4206-9caa-51d8fbd1b46b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:12:40.319304Z","iopub.execute_input":"2022-01-20T08:12:40.319871Z","iopub.status.idle":"2022-01-20T08:12:48.721019Z","shell.execute_reply.started":"2022-01-20T08:12:40.319830Z","shell.execute_reply":"2022-01-20T08:12:48.720207Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport transformers\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"262ea2b4-8965-457a-ac3f-36f3956394aa","_cell_guid":"f6f21706-c522-41f0-8eee-ec41acbad32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:12:48.722498Z","iopub.execute_input":"2022-01-20T08:12:48.722756Z","iopub.status.idle":"2022-01-20T08:12:53.980627Z","shell.execute_reply.started":"2022-01-20T08:12:48.722720Z","shell.execute_reply":"2022-01-20T08:12:53.979864Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\") \nbert_model.trainable = False","metadata":{"_uuid":"6bdfa15e-a5d6-4c58-b132-4e686af50782","_cell_guid":"b49e404e-c101-479b-9c40-39d581a7c7e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:12:53.982541Z","iopub.execute_input":"2022-01-20T08:12:53.983644Z","iopub.status.idle":"2022-01-20T08:13:16.093988Z","shell.execute_reply.started":"2022-01-20T08:12:53.983603Z","shell.execute_reply":"2022-01-20T08:13:16.093283Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8df57bac1fae496db3c04b2436b9267e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac50e3b4a4ae4efcb72e4187da7f74d9"}},"metadata":{}},{"name":"stderr","text":"2022-01-20 08:13:09.084732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:09.085934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:09.086720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:09.087599: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-20 08:13:09.088760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:09.089436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:09.090079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:13.681662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:13.682483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:13.683093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-20 08:13:13.683847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nSome layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=32\nmax_len=128\nEPOCHS=2","metadata":{"_uuid":"0a70ea60-c055-442d-a17b-92aa31a13d59","_cell_guid":"57e0530c-53c6-4440-8074-c165b041a7c5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:16.095333Z","iopub.execute_input":"2022-01-20T08:13:16.095685Z","iopub.status.idle":"2022-01-20T08:13:16.107670Z","shell.execute_reply.started":"2022-01-20T08:13:16.095646Z","shell.execute_reply":"2022-01-20T08:13:16.106695Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"./train.csv\",nrows=75000)\ntest_labels=pd.read_csv(\"./test_labels.csv\",nrows=75000)\n# train_data.head() \n# print(data.loc[0])\n# data.columns\n\n# data[\"toxic\"].value_counts()\ndata.head()\ntest_labels.head()","metadata":{"_uuid":"9ee0f4d2-28db-46e3-84bb-f3881399e437","_cell_guid":"ec8e3e79-f162-49a5-b966-2b0edae9ab30","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:16.109006Z","iopub.execute_input":"2022-01-20T08:13:16.109893Z","iopub.status.idle":"2022-01-20T08:13:16.616446Z","shell.execute_reply.started":"2022-01-20T08:13:16.109856Z","shell.execute_reply":"2022-01-20T08:13:16.615716Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 id  toxic  severe_toxic  obscene  threat  insult  \\\n0  00001cee341fdb12     -1            -1       -1      -1      -1   \n1  0000247867823ef7     -1            -1       -1      -1      -1   \n2  00013b17ad220c46     -1            -1       -1      -1      -1   \n3  00017563c3f7919a     -1            -1       -1      -1      -1   \n4  00017695ad8997eb     -1            -1       -1      -1      -1   \n\n   identity_hate  \n0             -1  \n1             -1  \n2             -1  \n3             -1  \n4             -1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"row_no=list(data.shape)[0]\nfor i in range(row_no):\n    row=data.loc[i]\n    row[\"comment_text\"]=re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", row[\"comment_text\"])","metadata":{"_uuid":"172c050f-530a-4cb9-bfeb-644d1d05e6bb","_cell_guid":"4e553d8c-573a-4b6a-a593-d18eed422cd3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:16.617847Z","iopub.execute_input":"2022-01-20T08:13:16.618101Z","iopub.status.idle":"2022-01-20T08:13:36.244726Z","shell.execute_reply.started":"2022-01-20T08:13:16.618074Z","shell.execute_reply":"2022-01-20T08:13:36.243950Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  cacher_needs_updating = self._check_is_chained_assignment_possible()\n","output_type":"stream"}]},{"cell_type":"code","source":"# x_train[0]\ndata.head()","metadata":{"_uuid":"acb671f4-2798-46d8-a568-1f0fd86dd624","_cell_guid":"f5302b70-2145-4634-87fa-67fff1e297de","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:36.245899Z","iopub.execute_input":"2022-01-20T08:13:36.246504Z","iopub.status.idle":"2022-01-20T08:13:36.258449Z","shell.execute_reply.started":"2022-01-20T08:13:36.246466Z","shell.execute_reply":"2022-01-20T08:13:36.257636Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n# [[0.09499235 0.09728582 0.20707038 0.2026455  0.18660283 0.21140313]]\nlabels =  test_labels[label_cols].values","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:13:36.259896Z","iopub.execute_input":"2022-01-20T08:13:36.260178Z","iopub.status.idle":"2022-01-20T08:13:36.274365Z","shell.execute_reply.started":"2022-01-20T08:13:36.260130Z","shell.execute_reply":"2022-01-20T08:13:36.273607Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# indexes = np.arange(12)\n# np.array(labels[indexes], dtype=\"int32\")\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:13:36.278734Z","iopub.execute_input":"2022-01-20T08:13:36.279560Z","iopub.status.idle":"2022-01-20T08:13:36.286294Z","shell.execute_reply.started":"2022-01-20T08:13:36.279516Z","shell.execute_reply":"2022-01-20T08:13:36.285502Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[-1, -1, -1, -1, -1, -1],\n       [-1, -1, -1, -1, -1, -1],\n       [-1, -1, -1, -1, -1, -1],\n       ...,\n       [-1, -1, -1, -1, -1, -1],\n       [-1, -1, -1, -1, -1, -1],\n       [ 0,  0,  0,  0,  0,  0]])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \ninput_sen=data[\"comment_text\"].values\n# print(input_sen)\ntrain_inputs,validation_inputs,train_labels,validation_labels=train_test_split(input_sen,labels,random_state=0,test_size=0.2) \n\n\nprint(train_inputs.shape)\nprint(train_labels.shape)\n\nprint(validation_inputs.shape)\nprint(validation_labels.shape)\n ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:13:36.287739Z","iopub.execute_input":"2022-01-20T08:13:36.288006Z","iopub.status.idle":"2022-01-20T08:13:36.934657Z","shell.execute_reply.started":"2022-01-20T08:13:36.287971Z","shell.execute_reply":"2022-01-20T08:13:36.932828Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(60000,)\n(60000, 6)\n(15000,)\n(15000, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BertSemanticDataGenerator(tf.keras.utils.Sequence): \n    def __init__(\n        self,\n        sentence_pairs,\n        labels,\n        batch_size=batch_size,\n        shuffle=True,\n        include_targets=True,\n    ):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.include_targets = include_targets\n         \n        \n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.indexes = np.arange(len(self.sentence_pairs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch.\n        return len(self.sentence_pairs) // self.batch_size\n\n    def __getitem__(self, idx):\n        # Retrieves the batch of index.\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        sentence_pairs = self.sentence_pairs[indexes]\n\n        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n        # encoded together and separated by [SEP] token.\n        encoded = self.tokenizer.batch_encode_plus(\n            sentence_pairs.tolist(),\n            add_special_tokens=True,\n            max_length=128,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n            pad_to_max_length=True,\n            return_tensors=\"tf\",\n        )   \n\n        bert_output = bert_model(**encoded)\n        \n        sequence_output = bert_output.last_hidden_state\n#         pooled_output = bert_output.pooler_output\n         \n        if self.include_targets:\n            labels = np.array(self.labels[indexes], dtype=\"int32\")\n            return sequence_output, labels\n        else:\n            return sequence_output\n\n    def on_epoch_end(self):\n        # Shuffle indexes after each epoch if shuffle is set to True.\n        if self.shuffle:\n            np.random.RandomState(42).shuffle(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:17:16.444041Z","iopub.execute_input":"2022-01-20T08:17:16.444594Z","iopub.status.idle":"2022-01-20T08:17:16.455985Z","shell.execute_reply.started":"2022-01-20T08:17:16.444555Z","shell.execute_reply":"2022-01-20T08:17:16.455196Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataset=BertSemanticDataGenerator(train_inputs,train_labels,shuffle=True)\nvalidation_dataset=BertSemanticDataGenerator(validation_inputs,validation_labels,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:17:26.841568Z","iopub.execute_input":"2022-01-20T08:17:26.842187Z","iopub.status.idle":"2022-01-20T08:17:33.360480Z","shell.execute_reply.started":"2022-01-20T08:17:26.842131Z","shell.execute_reply":"2022-01-20T08:17:33.359739Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# for d in tqdm(train_dataset):\n#     print(d)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:13:46.006980Z","iopub.execute_input":"2022-01-20T08:13:46.007282Z","iopub.status.idle":"2022-01-20T08:13:46.012632Z","shell.execute_reply.started":"2022-01-20T08:13:46.007242Z","shell.execute_reply":"2022-01-20T08:13:46.011120Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Sequence model\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope(): \n    input_layer = tf.keras.layers.Input(shape=(128, 768), name=None)\n#     input_layer=tf.reshape(input_layer, (128, 768), name=None) \n    \n    bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(input_layer) \n    \n    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n    dropout = tf.keras.layers.Dropout(0.1)(concat)    \n    output = tf.keras.layers.Dense(6, activation=\"softmax\")(dropout)\n    model = tf.keras.models.Model(\n        inputs=input_layer, outputs=output\n    )\n    \n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:34:17.961324Z","iopub.execute_input":"2022-01-20T08:34:17.962006Z","iopub.status.idle":"2022-01-20T08:34:18.398578Z","shell.execute_reply.started":"2022-01-20T08:34:17.961964Z","shell.execute_reply":"2022-01-20T08:34:18.397831Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 128, 768)]   0                                            \n__________________________________________________________________________________________________\nbidirectional_2 (Bidirectional) (None, 128, 128)     426496      input_4[0][0]                    \n__________________________________________________________________________________________________\nglobal_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_2[0][0]            \n__________________________________________________________________________________________________\nglobal_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 256)          0           global_average_pooling1d_3[0][0] \n                                                                 global_max_pooling1d_3[0][0]     \n__________________________________________________________________________________________________\ndropout_40 (Dropout)            (None, 256)          0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 6)            1542        dropout_40[0][0]                 \n==================================================================================================\nTotal params: 428,038\nTrainable params: 428,038\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"acc\"],\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:34:21.160603Z","iopub.execute_input":"2022-01-20T08:34:21.161121Z","iopub.status.idle":"2022-01-20T08:34:21.177180Z","shell.execute_reply.started":"2022-01-20T08:34:21.161083Z","shell.execute_reply":"2022-01-20T08:34:21.176476Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:34:27.841403Z","iopub.execute_input":"2022-01-20T08:34:27.841930Z","iopub.status.idle":"2022-01-20T08:53:40.224217Z","shell.execute_reply.started":"2022-01-20T08:34:27.841884Z","shell.execute_reply":"2022-01-20T08:53:40.223472Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"2022-01-20 08:34:28.140379: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\nop: \"FlatMapDataset\"\ninput: \"TensorDataset/_1\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_flat_map_fn_5115392\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n      }\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_FLOAT\n      type: DT_INT32\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n1875/1875 [==============================] - ETA: 0s - loss: -6.6213 - acc: 0.4993","output_type":"stream"},{"name":"stderr","text":"2022-01-20 08:42:13.992122: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\nop: \"FlatMapDataset\"\ninput: \"TensorDataset/_1\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_flat_map_fn_7840452\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n      }\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_FLOAT\n      type: DT_INT32\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"},{"name":"stdout","text":"1875/1875 [==============================] - 579s 307ms/step - loss: -6.6213 - acc: 0.4993 - val_loss: -6.3793 - val_acc: 0.9992\nEpoch 2/2\n1875/1875 [==============================] - 573s 306ms/step - loss: -6.6176 - acc: 0.5053 - val_loss: -6.3483 - val_acc: 0.9992\n","output_type":"stream"}]},{"cell_type":"code","source":"s4 = 'fuck'\nsentence_pairs = np.array([s4])\ntest_data = BertSemanticDataGenerator(\n        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n    )\n\npro=model.predict(test_data)\nprint(pro)\nprint(label_cols[np.argmax(pro)])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:55:39.262518Z","iopub.execute_input":"2022-01-20T08:55:39.262773Z","iopub.status.idle":"2022-01-20T08:55:42.802814Z","shell.execute_reply.started":"2022-01-20T08:55:39.262742Z","shell.execute_reply":"2022-01-20T08:55:42.801976Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n2022-01-20 08:55:42.592112: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\nop: \"FlatMapDataset\"\ninput: \"TensorDataset/_1\"\nattr {\n  key: \"Targuments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"f\"\n  value {\n    func {\n      name: \"__inference_Dataset_flat_map_flat_map_fn_11926300\"\n    }\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_FLOAT\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"},{"name":"stdout","text":"[[0.2571675  0.21692714 0.16095094 0.0555994  0.1521901  0.15716496]]\ntoxic\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"my_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-20T08:55:56.071902Z","iopub.execute_input":"2022-01-20T08:55:56.072180Z","iopub.status.idle":"2022-01-20T08:55:56.121035Z","shell.execute_reply.started":"2022-01-20T08:55:56.072136Z","shell.execute_reply":"2022-01-20T08:55:56.120345Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# from keras.preprocessing.sequence import pad_sequences\n# # to convert the iput ids array in same size(column no=max(column no))\n# tokenizer=transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n# max_length=128\n# bert_model=transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n# bert_model.trainable=False\n\n# def tokenize(data,tokenizer=tokenizer,max_length=max_length):\n# #     input_ids=[]\n# #     attention_masks=[]\n#     bert_outputs=[]\n#     for sentence in tqdm(data):\n        \n#         encoded_data=tokenizer.batch_encode_plus(\n#                         sentence,\n#                         add_special_tokens=True,\n#                         max_length=max_length,\n#                         truncation=True,\n#                         return_attention_mask=True,\n#                         return_token_type_ids=True,\n#                         pad_to_max_length=True,\n#                         return_tensors=\"tf\",\n#                     )\n\n# #         input_id=np.array(encoded_data[\"input_ids\"],dtype=\"int32\")\n# #         attention_mask=np.array(encoded_data[\"attention_mask\"],dtype=\"int32\") \n        \n#         bert_output=bert_model(**encoded_data)\n#         sequence_output = bert_output.last_hidden_state\n#         bert_outputs.append(sequence_output)\n#     return bert_outputs\n# #         input_ids.append(input_id)\n# #         attention_masks.append(attention_mask)\n        \n# #     return [input_ids,attention_masks]\n\n# bert_op=tokenize(data['comment_text'])\n# # input_ids=pad_sequences(bert_op[0],maxlen=max_length,dtype='long',value=0,truncating=\"post\",padding=\"post\")\n# # attention_masks=bert_op[1]\n# # bert_op.shape","metadata":{"_uuid":"b3c9a14a-97f5-4524-8ee3-1f26b7cd3bc3","_cell_guid":"89d44245-7af1-442a-bdd4-4a9c3e2185f3","execution":{"iopub.status.busy":"2022-01-20T08:13:46.874007Z","iopub.status.idle":"2022-01-20T08:13:46.874483Z","shell.execute_reply.started":"2022-01-20T08:13:46.874221Z","shell.execute_reply":"2022-01-20T08:13:46.874245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(bert_op)","metadata":{"_uuid":"8959229a-8e2d-4b3b-aac2-0fb6ce9a033d","_cell_guid":"54912915-4e18-4d75-91e8-026f9ce2e866","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.876039Z","iopub.status.idle":"2022-01-20T08:13:46.876487Z","shell.execute_reply.started":"2022-01-20T08:13:46.876251Z","shell.execute_reply":"2022-01-20T08:13:46.876274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attention_masks=np.array(attention_masks)\n# attention_masks=pad_sequences(attention_masks,maxlen=max_length,dtype='long',value=0,truncating=\"post\",padding=\"post\")\n# input_ids.shape\n# attention_masks.shape","metadata":{"_uuid":"d3dc7179-5583-4c1a-b5ba-8e66a821990e","_cell_guid":"c50fc5aa-5eb4-4d52-975d-b04430e24c0b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.877823Z","iopub.status.idle":"2022-01-20T08:13:46.878246Z","shell.execute_reply.started":"2022-01-20T08:13:46.878009Z","shell.execute_reply":"2022-01-20T08:13:46.878031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # creating batched dataset\n# epochs=2\n# def create_batch_dataset(data,epochs=epochs,batch_size=batch_size,buffer_size=1000,train=True):\n#     dataset=tf.data.Dataset.from_tensor_slices(data)\n# #     print(dataset.as_numpy_iterator())\n#     if train:\n#         dataset=dataset.shuffle(buffer_size=buffer_size)\n#         # uses for shuffling the dataset.Select the first buffer_size element from dataset\n#     dataset=dataset.repeat(epochs)\n#     # just repeat the whole dataset\n#     dataset=dataset.batch(batch_size=batch_size)\n#     # devide the whole dataset into batch size and create an array of array\n#     if train:\n#         dataset=dataset.prefetch(1)\n#     #     It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two \n#     # elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 \n#     # batches, of 20 examples each).\n#     return dataset\n# train_dataset=create_batch_dataset((train_inputs,train_masks,train_labels),train=True)\n# validation_dataset=create_batch_dataset((validation_inputs,validation_masks,validation_labels),train=True)","metadata":{"_uuid":"d627f4cb-eafd-4f52-99d1-cacead47c1ca","_cell_guid":"0af7aedf-d747-4590-bec8-37a35f99eadb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.879706Z","iopub.status.idle":"2022-01-20T08:13:46.880202Z","shell.execute_reply.started":"2022-01-20T08:13:46.879918Z","shell.execute_reply":"2022-01-20T08:13:46.879943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train_dataset.as_numpy_iterator())\n# print(validation_dataset.as_numpy_iterator())","metadata":{"_uuid":"73f7786f-9ca0-4f29-a82d-650477b7d2bc","_cell_guid":"a59210ea-f3ff-40dc-adc3-43704a4db6b2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.881514Z","iopub.status.idle":"2022-01-20T08:13:46.881919Z","shell.execute_reply.started":"2022-01-20T08:13:46.881699Z","shell.execute_reply":"2022-01-20T08:13:46.881721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list(train_dataset.as_numpy_iterator())[0][0].shape","metadata":{"_uuid":"427fde78-4770-4549-ae20-645d3f36761f","_cell_guid":"78a49bf9-1666-4840-905a-bca000fd79c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.883029Z","iopub.status.idle":"2022-01-20T08:13:46.883994Z","shell.execute_reply.started":"2022-01-20T08:13:46.883753Z","shell.execute_reply":"2022-01-20T08:13:46.883777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i, (token_ids, masks, labels) in enumerate(tqdm(train_dataset)):\n#             print(token_ids.shape)","metadata":{"_uuid":"81665e1f-ce0f-4bff-9771-2257c2ee4ede","_cell_guid":"ea775813-0198-4389-9854-204d13b6e189","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.885318Z","iopub.status.idle":"2022-01-20T08:13:46.885735Z","shell.execute_reply.started":"2022-01-20T08:13:46.885513Z","shell.execute_reply":"2022-01-20T08:13:46.885535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/nkaenzig/bert-tensorflow-2-huggingface-transformers\n# https://www.kaggle.com/satyamkryadav/bert-model-96-77/notebook","metadata":{"_uuid":"cf97dec3-abcc-41fb-92d7-bfa598eacba0","_cell_guid":"0d34a9f6-e683-4261-b26e-d5e31d2ef1e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-20T08:13:46.887047Z","iopub.status.idle":"2022-01-20T08:13:46.887479Z","shell.execute_reply.started":"2022-01-20T08:13:46.887245Z","shell.execute_reply":"2022-01-20T08:13:46.887267Z"},"trusted":true},"execution_count":null,"outputs":[]}]}