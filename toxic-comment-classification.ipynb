{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip ","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:09:49.926883Z","iopub.execute_input":"2022-01-19T19:09:49.927142Z","iopub.status.idle":"2022-01-19T19:10:08.694790Z","shell.execute_reply.started":"2022-01-19T19:09:49.927114Z","shell.execute_reply":"2022-01-19T19:10:08.693924Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Archive:  ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\nreplace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\nreplace test_labels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\nreplace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\nreplace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-01-19T18:40:46.879353Z","iopub.execute_input":"2022-01-19T18:40:46.879615Z","iopub.status.idle":"2022-01-19T18:40:55.644969Z","shell.execute_reply.started":"2022-01-19T18:40:46.879584Z","shell.execute_reply":"2022-01-19T18:40:55.644153Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport transformers\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:10:13.636255Z","iopub.execute_input":"2022-01-19T19:10:13.636554Z","iopub.status.idle":"2022-01-19T19:10:19.247250Z","shell.execute_reply.started":"2022-01-19T19:10:13.636519Z","shell.execute_reply":"2022-01-19T19:10:19.246484Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer=transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\nmax_length=128","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:10:20.996133Z","iopub.execute_input":"2022-01-19T19:10:20.996552Z","iopub.status.idle":"2022-01-19T19:10:23.904166Z","shell.execute_reply.started":"2022-01-19T19:10:20.996514Z","shell.execute_reply":"2022-01-19T19:10:23.903443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size=32\nmax_len=128\nEPOCHS=2","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:10:23.906590Z","iopub.execute_input":"2022-01-19T19:10:23.907023Z","iopub.status.idle":"2022-01-19T19:10:23.912413Z","shell.execute_reply.started":"2022-01-19T19:10:23.906982Z","shell.execute_reply":"2022-01-19T19:10:23.911352Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"./train.csv\",nrows=1000)\ntest_labels=pd.read_csv(\"./test_labels.csv\",nrows=1000)\n# train_data.head() \n# print(data.loc[0])\n# data.columns\n\n# data[\"toxic\"].value_counts()\ndata.head()\ntest_labels.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:11:50.716131Z","iopub.execute_input":"2022-01-19T19:11:50.716806Z","iopub.status.idle":"2022-01-19T19:11:50.742045Z","shell.execute_reply.started":"2022-01-19T19:11:50.716668Z","shell.execute_reply":"2022-01-19T19:11:50.741330Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                 id  toxic  severe_toxic  obscene  threat  insult  \\\n0  00001cee341fdb12     -1            -1       -1      -1      -1   \n1  0000247867823ef7     -1            -1       -1      -1      -1   \n2  00013b17ad220c46     -1            -1       -1      -1      -1   \n3  00017563c3f7919a     -1            -1       -1      -1      -1   \n4  00017695ad8997eb     -1            -1       -1      -1      -1   \n\n   identity_hate  \n0             -1  \n1             -1  \n2             -1  \n3             -1  \n4             -1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"row_no=list(data.shape)[0]\nfor i in range(row_no):\n    row=data.loc[i]\n    row[\"comment_text\"]=re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", row[\"comment_text\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:11:52.886117Z","iopub.execute_input":"2022-01-19T19:11:52.886379Z","iopub.status.idle":"2022-01-19T19:11:53.141995Z","shell.execute_reply.started":"2022-01-19T19:11:52.886351Z","shell.execute_reply":"2022-01-19T19:11:53.141181Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  cacher_needs_updating = self._check_is_chained_assignment_possible()\n","output_type":"stream"}]},{"cell_type":"code","source":"# x_train[0]\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:11:59.317265Z","iopub.execute_input":"2022-01-19T19:11:59.317830Z","iopub.status.idle":"2022-01-19T19:11:59.330404Z","shell.execute_reply.started":"2022-01-19T19:11:59.317789Z","shell.execute_reply":"2022-01-19T19:11:59.329481Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n# to convert the iput ids array in same size(column no=max(column no))\ntokenizer=transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\nmax_length=128\n\n\ndef tokenize(data,tokenizer=tokenizer,max_length=max_length):\n    input_ids=[]\n    attention_masks=[]\n    for sentence in tqdm(data):\n        \n        encoded_data=tokenizer.batch_encode_plus(\n                        sentence,\n                        add_special_tokens=True,\n                        max_length=max_length,\n                        truncation=True,\n                        return_attention_mask=True,\n                        return_token_type_ids=True,\n                        pad_to_max_length=True,\n                        return_tensors=\"tf\",\n                    )\n\n        input_id=np.array(encoded_data[\"input_ids\"],dtype=\"int32\")\n        attention_mask=np.array(encoded_data[\"attention_mask\"],dtype=\"int32\") \n        \n        input_ids.append(input_id)\n        attention_masks.append(attention_mask)\n        \n    return [input_ids,attention_masks]\n\nbert_op=tokenize(data['comment_text'])\ninput_ids=pad_sequences(bert_op[0],maxlen=max_length,dtype='long',value=0,truncating=\"post\",padding=\"post\")\nattention_masks=bert_op[1]","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:31:13.147472Z","iopub.execute_input":"2022-01-19T19:31:13.148128Z","iopub.status.idle":"2022-01-19T19:32:00.219600Z","shell.execute_reply.started":"2022-01-19T19:31:13.148084Z","shell.execute_reply":"2022-01-19T19:32:00.218701Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f1e1e2a316a4d8796ecf2236e90ee05"}},"metadata":{}}]},{"cell_type":"code","source":"attention_masks=np.array(attention_masks)\nattention_masks=pad_sequences(attention_masks,maxlen=max_length,dtype='long',value=0,truncating=\"post\",padding=\"post\")\ninput_ids.shape\nattention_masks.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:37:54.276968Z","iopub.execute_input":"2022-01-19T19:37:54.277891Z","iopub.status.idle":"2022-01-19T19:37:54.353746Z","shell.execute_reply.started":"2022-01-19T19:37:54.277851Z","shell.execute_reply":"2022-01-19T19:37:54.352827Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(1000, 128, 128)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nlabels=data[label_cols].values\n\ntrain_inputs,validation_inputs,train_labels,validation_labels=train_test_split(input_ids,labels,random_state=0,test_size=0.2)\ntrain_masks,validation_masks,_,_=train_test_split(attention_masks,labels,random_state=0,test_size=0.2)\n\n\nprint(train_inputs.shape)\nprint(train_labels.shape)\n\nprint(validation_inputs.shape)\nprint(validation_labels.shape)\n\nprint(train_masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:38:03.276793Z","iopub.execute_input":"2022-01-19T19:38:03.277064Z","iopub.status.idle":"2022-01-19T19:38:03.362788Z","shell.execute_reply.started":"2022-01-19T19:38:03.277035Z","shell.execute_reply":"2022-01-19T19:38:03.361982Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"(800, 128, 128)\n(800, 6)\n(200, 128, 128)\n(200, 6)\n(800, 128, 128)\n","output_type":"stream"}]},{"cell_type":"code","source":"# creating batched dataset\nepochs=2\ndef create_batch_dataset(data,epochs=epochs,batch_size=batch_size,buffer_size=1000,train=True):\n    dataset=tf.data.Dataset.from_tensor_slices(data)\n    if train:\n        dataset=dataset.shuffle(buffer_size=buffer_size)\n        # uses for shuffling the dataset.Select the first buffer_size element from dataset\n    dataset=dataset.repeat(epochs)\n    # just repeat the whole dataset\n    dataset=dataset.batch(batch_size=batch_size)\n    # devide the whole dataset into batch size and create an array of array\n    if train:\n        dataset=dataset.prefetch(1)\n    #     It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two \n    # elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 \n    # batches, of 20 examples each).\n    return dataset\ntrain_dataset=create_batch_dataset((train_inputs,train_masks,train_labels),train=True)\nvalidation_dataset=create_batch_dataset((validation_inputs,validation_masks,validation_labels),train=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:40:38.117060Z","iopub.execute_input":"2022-01-19T19:40:38.117743Z","iopub.status.idle":"2022-01-19T19:40:38.518291Z","shell.execute_reply.started":"2022-01-19T19:40:38.117684Z","shell.execute_reply":"2022-01-19T19:40:38.517591Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(train_dataset)\nprint(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:40:41.826935Z","iopub.execute_input":"2022-01-19T19:40:41.827243Z","iopub.status.idle":"2022-01-19T19:40:41.832733Z","shell.execute_reply.started":"2022-01-19T19:40:41.827210Z","shell.execute_reply":"2022-01-19T19:40:41.831883Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"<PrefetchDataset shapes: ((None, 128, 128), (None, 128, 128), (None, 6)), types: (tf.int64, tf.int64, tf.int64)>\n<PrefetchDataset shapes: ((None, 128, 128), (None, 128, 128), (None, 6)), types: (tf.int64, tf.int64, tf.int64)>\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://www.kaggle.com/nkaenzig/bert-tensorflow-2-huggingface-transformers","metadata":{},"execution_count":null,"outputs":[]}]}