{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip","metadata":{"_uuid":"0d89fec7-5d44-4336-9da5-469346fa2def","_cell_guid":"b5e152ff-6613-4ecf-a299-d475fca64685","execution":{"iopub.status.busy":"2022-01-25T13:16:58.936985Z","iopub.execute_input":"2022-01-25T13:16:58.937780Z","iopub.status.idle":"2022-01-25T13:17:03.371869Z","shell.execute_reply.started":"2022-01-25T13:16:58.937679Z","shell.execute_reply":"2022-01-25T13:17:03.371105Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Archive:  ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n  inflating: train.csv               \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n  inflating: test_labels.csv         \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n  inflating: sample_submission.csv   \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n  inflating: test.csv                \n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers \n# save the best weight ,means less loss valued trained batch \n# do some warm up step initially to make it more effiecient","metadata":{"_uuid":"a399aa52-641d-4b0b-ae94-428c6c4e20ff","_cell_guid":"76f4bbc5-95f6-4206-9caa-51d8fbd1b46b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:17:03.374241Z","iopub.execute_input":"2022-01-25T13:17:03.374816Z","iopub.status.idle":"2022-01-25T13:17:11.983383Z","shell.execute_reply.started":"2022-01-25T13:17:03.374776Z","shell.execute_reply":"2022-01-25T13:17:11.982567Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport transformers\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"262ea2b4-8965-457a-ac3f-36f3956394aa","_cell_guid":"f6f21706-c522-41f0-8eee-ec41acbad32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:17:11.984927Z","iopub.execute_input":"2022-01-25T13:17:11.985183Z","iopub.status.idle":"2022-01-25T13:17:17.547361Z","shell.execute_reply.started":"2022-01-25T13:17:11.985148Z","shell.execute_reply":"2022-01-25T13:17:17.546644Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\") \nbert_model.trainable = False","metadata":{"_uuid":"6bdfa15e-a5d6-4c58-b132-4e686af50782","_cell_guid":"b49e404e-c101-479b-9c40-39d581a7c7e6","execution":{"iopub.status.busy":"2022-01-25T13:17:17.549399Z","iopub.execute_input":"2022-01-25T13:17:17.549634Z","iopub.status.idle":"2022-01-25T13:17:52.688601Z","shell.execute_reply.started":"2022-01-25T13:17:17.549604Z","shell.execute_reply":"2022-01-25T13:17:52.687886Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5fd012759b143719085d7cd0f642874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dcec95804244abb8e7a298d631acfa8"}},"metadata":{}},{"name":"stderr","text":"2022-01-25 13:17:45.932533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:45.933518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:45.934186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:45.935022: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-25 13:17:45.936513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:45.937182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:45.937817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:50.370804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:50.371630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:50.372302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-25 13:17:50.372899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nSome layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=32\nmax_len=128\nEPOCHS=2","metadata":{"_uuid":"0a70ea60-c055-442d-a17b-92aa31a13d59","_cell_guid":"57e0530c-53c6-4440-8074-c165b041a7c5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:17:52.689985Z","iopub.execute_input":"2022-01-25T13:17:52.690260Z","iopub.status.idle":"2022-01-25T13:17:52.694831Z","shell.execute_reply.started":"2022-01-25T13:17:52.690221Z","shell.execute_reply":"2022-01-25T13:17:52.693843Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"./train.csv\") ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:52.695998Z","iopub.execute_input":"2022-01-25T13:17:52.697207Z","iopub.status.idle":"2022-01-25T13:17:53.482385Z","shell.execute_reply.started":"2022-01-25T13:17:52.697182Z","shell.execute_reply":"2022-01-25T13:17:53.481620Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# count the individual data\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] \npositive_comment=data[data[label_cols].sum(axis=1)==0]\ntoxic_comment=data[data[label_cols].sum(axis=1)>0]\nno_value=data[data[label_cols].sum(axis=1)=='']\n\n# print(len(positive_comment)) #143346\n# print(len(toxic_comment))# 16225\n# print(len(no_value))# 16225\n\n# random samling from positve commnet to tkae out of 14000 comment\n\n# toxic_comment=data[data['toxic']==1]\n# toxic_comment.shape\n## drop some toxic comment for better prediction\n\n# purely toxic\nconditions = [\n    (toxic_comment['toxic']==1)&\n    (toxic_comment['severe_toxic']==0) & (toxic_comment['obscene']==0)&\n    (toxic_comment['threat']==0) & (toxic_comment['insult']==0)&\n    (toxic_comment['identity_hate']==0)\n    ]\npurely_toxic=toxic_comment[conditions[0]]\nprint(purely_toxic.shape)\npurely_toxic.sample(frac = 1)\n# mixed toxic\nmixed_toxic=toxic_comment[toxic_comment['toxic']==1]\nprint(mixed_toxic.shape)\n\n# drop pure toxic\ntoxic_comment.drop(purely_toxic.index,inplace=True)\n\ndata=pd.concat([\n    toxic_comment,\n    purely_toxic.sample(frac=0.6),\n    positive_comment.sample(n=20_000)\n])\n\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:53.483738Z","iopub.execute_input":"2022-01-25T13:17:53.484080Z","iopub.status.idle":"2022-01-25T13:17:53.554428Z","shell.execute_reply.started":"2022-01-25T13:17:53.484028Z","shell.execute_reply":"2022-01-25T13:17:53.553604Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(5666, 8)\n(15294, 8)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(33959, 8)"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nconditions = [\n    (data['toxic']==1)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\ntoxic_comment=data[conditions[0]]\n\nconditions1 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==1) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nsevere_toxic_comment=data[conditions1[0]]\n\nconditions2 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==1)&\n    (data['identity_hate']==0)\n    ]\ninsult_comment=data[conditions2[0]]\n\nconditions3 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==1)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nobscene_comment=data[conditions3[0]]\n\nconditions4 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==1) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nthreat_comment=data[conditions4[0]] \nprint(data.shape)\n\nlabel_bar = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult']\nlabel_data=[toxic_comment.shape[0],severe_toxic_comment.shape[0],obscene_comment.shape[0],threat_comment.shape[0],insult_comment.shape[0]]\n\nfig=plt.figure(figsize=(10,5)) \nplt.bar(label_bar,label_data,color=\"red\",width=0.3)\nplt.xlabel(\"Comment Sense\")\nplt.ylabel(\"count of Sense\")\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:53.555768Z","iopub.execute_input":"2022-01-25T13:17:53.556099Z","iopub.status.idle":"2022-01-25T13:17:53.769414Z","shell.execute_reply.started":"2022-01-25T13:17:53.556063Z","shell.execute_reply":"2022-01-25T13:17:53.768739Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(33959, 8)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"threat_comment.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:53.770656Z","iopub.execute_input":"2022-01-25T13:17:53.770888Z","iopub.status.idle":"2022-01-25T13:17:53.776319Z","shell.execute_reply.started":"2022-01-25T13:17:53.770855Z","shell.execute_reply":"2022-01-25T13:17:53.775476Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(22, 8)"},"metadata":{}}]},{"cell_type":"code","source":"# add up a column positive\nconditions = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nvalues = [1]\n\n# data['positive']=np.where(data['toxic']==0 and data['severe_toxic']==0 and  and  and  and ,1,0)\ndata['positive']=np.select(conditions,values)\n\nlabel_cols.append(\"positive\")\n\nprint(data.shape)\npositive_comment=data[data[label_cols].sum(axis=1)==1]\nprint(len(positive_comment))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:53.779791Z","iopub.execute_input":"2022-01-25T13:17:53.780066Z","iopub.status.idle":"2022-01-25T13:17:53.808359Z","shell.execute_reply.started":"2022-01-25T13:17:53.780018Z","shell.execute_reply":"2022-01-25T13:17:53.807702Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(33959, 9)\n24094\n","output_type":"stream"}]},{"cell_type":"code","source":"data[\"comment_text\"]=data[\"comment_text\"].map(lambda x:re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x))\n# removing stop words\n","metadata":{"_uuid":"172c050f-530a-4cb9-bfeb-644d1d05e6bb","_cell_guid":"4e553d8c-573a-4b6a-a593-d18eed422cd3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:17:53.810248Z","iopub.execute_input":"2022-01-25T13:17:53.811292Z","iopub.status.idle":"2022-01-25T13:17:57.167663Z","shell.execute_reply.started":"2022-01-25T13:17:53.811256Z","shell.execute_reply":"2022-01-25T13:17:57.166928Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# sense_count_pd=pd.DataFrame(data[label_cols].value_counts()) \n# sense_count_pd","metadata":{"_uuid":"acb671f4-2798-46d8-a568-1f0fd86dd624","_cell_guid":"f5302b70-2145-4634-87fa-67fff1e297de","execution":{"iopub.status.busy":"2022-01-25T13:17:57.168977Z","iopub.execute_input":"2022-01-25T13:17:57.169242Z","iopub.status.idle":"2022-01-25T13:17:57.173844Z","shell.execute_reply.started":"2022-01-25T13:17:57.169200Z","shell.execute_reply":"2022-01-25T13:17:57.172685Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"labels =  data[label_cols].values","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:57.175038Z","iopub.execute_input":"2022-01-25T13:17:57.175351Z","iopub.status.idle":"2022-01-25T13:17:57.184401Z","shell.execute_reply.started":"2022-01-25T13:17:57.175315Z","shell.execute_reply":"2022-01-25T13:17:57.183726Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:57.185618Z","iopub.execute_input":"2022-01-25T13:17:57.185973Z","iopub.status.idle":"2022-01-25T13:17:57.193526Z","shell.execute_reply.started":"2022-01-25T13:17:57.185938Z","shell.execute_reply":"2022-01-25T13:17:57.192644Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(33959, 7)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \ninput_sen=data[\"comment_text\"].values\n# print(input_sen)\ntrain_inputs,validation_inputs,train_labels,validation_labels=train_test_split(input_sen,labels,random_state=0,test_size=0.1) \n\n\nprint(train_inputs.shape)\nprint(train_labels.shape)\n\nprint(validation_inputs.shape)\nprint(validation_labels.shape)\n ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:57.195147Z","iopub.execute_input":"2022-01-25T13:17:57.195501Z","iopub.status.idle":"2022-01-25T13:17:57.933462Z","shell.execute_reply.started":"2022-01-25T13:17:57.195438Z","shell.execute_reply":"2022-01-25T13:17:57.932694Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(30563,)\n(30563, 7)\n(3396,)\n(3396, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BertSemanticDataGenerator(tf.keras.utils.Sequence): \n    def __init__(\n        self,\n        sentence_pairs,\n        labels,\n        batch_size=batch_size,\n        shuffle=True,\n        include_targets=True,\n    ):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.include_targets = include_targets\n         \n        \n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.indexes = np.arange(len(self.sentence_pairs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch.\n        return len(self.sentence_pairs) // self.batch_size\n\n    def __getitem__(self, idx):\n        # Retrieves the batch of index.\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        sentence_pairs = self.sentence_pairs[indexes]\n\n        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n        # encoded together and separated by [SEP] token. \n        encoded = self.tokenizer.batch_encode_plus(\n            sentence_pairs.tolist(),\n            add_special_tokens=True,\n            max_length=128,\n            return_attention_mask=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,truncation=True,\n            return_tensors=\"tf\",\n        )   \n\n        bert_output = bert_model(**encoded)\n        \n        sequence_output = bert_output.last_hidden_state \n         \n        if self.include_targets:\n            labels = np.array(self.labels[indexes], dtype=\"int32\")\n            return sequence_output, labels\n        else:\n            return sequence_output\n\n    def on_epoch_end(self): \n        if self.shuffle:\n            np.random.RandomState(42).shuffle(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:57.934831Z","iopub.execute_input":"2022-01-25T13:17:57.935209Z","iopub.status.idle":"2022-01-25T13:17:57.946519Z","shell.execute_reply.started":"2022-01-25T13:17:57.935173Z","shell.execute_reply":"2022-01-25T13:17:57.945716Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset=BertSemanticDataGenerator(train_inputs,train_labels,shuffle=True)\nvalidation_dataset=BertSemanticDataGenerator(validation_inputs,validation_labels,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:17:57.948187Z","iopub.execute_input":"2022-01-25T13:17:57.948590Z","iopub.status.idle":"2022-01-25T13:18:06.564007Z","shell.execute_reply.started":"2022-01-25T13:17:57.948553Z","shell.execute_reply":"2022-01-25T13:18:06.563259Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5d7688c1bca48b982642c4b923c795f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8440803dec348478643fdda5d9b7f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47320c5d929c4740862de18edb598fa1"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset[18]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:18:06.565333Z","iopub.execute_input":"2022-01-25T13:18:06.565561Z","iopub.status.idle":"2022-01-25T13:18:06.820664Z","shell.execute_reply.started":"2022-01-25T13:18:06.565530Z","shell.execute_reply":"2022-01-25T13:18:06.819953Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(32, 128, 768), dtype=float32, numpy=\n array([[[-0.2356413 ,  0.406116  , -0.33087343, ..., -0.42918846,\n           0.2737188 ,  0.38447618],\n         [ 0.6483493 ,  0.855512  , -0.21963021, ..., -0.80041593,\n           0.0995321 ,  0.3702189 ],\n         [ 0.73632777,  1.0880098 ,  0.12472107, ..., -0.4709814 ,\n           0.27726206,  0.1451369 ],\n         ...,\n         [-0.17011668,  0.06911267,  0.4082659 , ...,  0.23945817,\n           0.11182415,  0.21066928],\n         [-0.22844726, -0.00451886,  0.25637403, ...,  0.15796545,\n           0.20725945,  0.14868356],\n         [ 0.08379127,  0.14762473,  0.42451936, ...,  0.10045649,\n           0.14241591,  0.24424858]],\n \n        [[-0.043904  ,  0.05509792,  0.1848419 , ..., -0.9152613 ,\n           0.6653263 ,  0.39571792],\n         [ 0.7599528 ,  0.10011499,  0.07745426, ...,  0.04047047,\n           0.88367   ,  0.30715588],\n         [-0.147672  ,  0.60877246,  0.46983457, ..., -0.3191585 ,\n           0.00533924, -0.5008034 ],\n         ...,\n         [ 0.0307932 , -0.18637158, -0.00583188, ...,  0.3302454 ,\n           0.40906456, -0.14611605],\n         [ 0.055044  , -0.16862026, -0.02198634, ...,  0.32154495,\n           0.4051432 , -0.2343561 ],\n         [ 0.2444812 ,  0.02482083,  0.29479122, ...,  0.00581266,\n           0.24946208, -0.14085218]],\n \n        [[-0.18814358, -0.06300065, -0.51812875, ..., -0.23454808,\n           0.26241946,  0.6730274 ],\n         [-0.46185318, -0.9824072 ,  0.27829078, ..., -0.24820712,\n           0.80734986, -0.5945693 ],\n         [ 0.79670465, -0.49683306, -0.05549453, ..., -0.13677421,\n           0.01865448,  0.14629363],\n         ...,\n         [-0.6561166 , -0.4018135 ,  0.17169175, ..., -0.4922398 ,\n          -0.03928029,  0.7486    ],\n         [ 0.32496178, -0.19885993, -0.00561757, ...,  0.05209712,\n           0.3261575 ,  0.43586758],\n         [ 0.5943616 ,  0.27070656, -0.43222436, ...,  0.12175906,\n          -0.33070225,  0.03000399]],\n \n        ...,\n \n        [[ 0.05902299,  0.78710943, -0.02952106, ..., -0.6669887 ,\n           0.8789189 , -0.06871382],\n         [ 0.8241203 ,  0.7088387 , -0.7792709 , ..., -0.5187823 ,\n           0.5762819 ,  0.16335434],\n         [-0.19998084, -0.11399213, -0.71087104, ...,  0.1119845 ,\n           0.61702585, -0.7490603 ],\n         ...,\n         [ 0.09425515, -0.08506492, -0.28848475, ..., -0.00763939,\n           0.52064365, -0.71166867],\n         [ 0.3721305 ,  0.36104032,  0.10072424, ..., -0.1580551 ,\n           0.14949945, -0.39709514],\n         [ 0.4405602 ,  0.39888352,  0.16395172, ..., -0.2731937 ,\n           0.25304198, -0.4429716 ]],\n \n        [[-0.49968818,  0.22475836, -0.0205129 , ..., -0.48165494,\n           0.49554315,  0.13247512],\n         [ 0.01386992,  0.04075903, -0.17748785, ...,  0.0774868 ,\n           0.49090636,  0.6154967 ],\n         [-0.27264452,  0.12318017,  0.44261843, ...,  0.09476395,\n          -0.36023265,  0.7084333 ],\n         ...,\n         [-0.11032799,  0.05910998,  0.40952867, ..., -0.09338252,\n           0.2683912 , -0.06341444],\n         [-0.27036095, -0.45377946, -0.28886056, ...,  0.44083047,\n           0.5604326 , -0.48071888],\n         [-0.30963796, -0.07268788,  0.4371993 , ..., -0.01666306,\n           0.31302866, -0.10130525]],\n \n        [[-0.08996707,  0.20239013, -0.54440546, ..., -0.41583803,\n           0.80494416,  0.6310749 ],\n         [ 0.16193847,  0.37082377, -0.27975675, ..., -0.02282112,\n           1.104487  ,  0.86401254],\n         [-0.07703843,  0.535071  , -0.06562185, ..., -0.70477486,\n           0.83485204,  0.87038285],\n         ...,\n         [-0.21684198, -0.61363065,  0.00883408, ...,  0.40512627,\n           0.35354117,  0.14258495],\n         [-0.12698843, -0.03826079,  0.41627198, ...,  0.06665855,\n           0.35306868,  0.3746864 ],\n         [ 0.07765055,  0.24167353,  0.39604992, ..., -0.03185544,\n           0.32303005,  0.34343183]]], dtype=float32)>,\n array([[0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 1, 0, 1, 1, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 0, 1, 0, 0],\n        [1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0],\n        [1, 0, 1, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 0, 0, 0, 0],\n        [1, 1, 1, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 1, 0, 1, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0],\n        [1, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 0, 1, 0, 0],\n        [1, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 1, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1]], dtype=int32))"},"metadata":{}}]},{"cell_type":"code","source":"input_layer = tf.keras.layers.Input(shape=(128, 768), name=None)  \n\n\nbi_lstm_layer=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences=True))(input_layer)\nmax_pooling1=tf.keras.layers.GlobalMaxPooling1D()(bi_lstm_layer)\naverage_pooling1=tf.keras.layers.GlobalAveragePooling1D()(bi_lstm_layer)\nsch_pooling=tf.keras.layers.concatenate([max_pooling1,average_pooling1])\ndropout1=tf.keras.layers.Dropout(0.1)(sch_pooling)\n\n \n\nflat=tf.keras.layers.Flatten()(dropout1) \noutput = tf.keras.layers.Dense(7, activation=\"softmax\")(flat)\nmodel = tf.keras.models.Model(inputs=input_layer, outputs=output)\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:18:06.821950Z","iopub.execute_input":"2022-01-25T13:18:06.822288Z","iopub.status.idle":"2022-01-25T13:18:07.290450Z","shell.execute_reply.started":"2022-01-25T13:18:06.822248Z","shell.execute_reply":"2022-01-25T13:18:07.289725Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 128, 768)]   0                                            \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, 128, 128)     426496      input_1[0][0]                    \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 256)          0           global_max_pooling1d[0][0]       \n                                                                 global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 256)          0           dropout_37[0][0]                 \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 7)            1799        flatten[0][0]                    \n==================================================================================================\nTotal params: 428,295\nTrainable params: 428,295\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.compile()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:18:07.291676Z","iopub.execute_input":"2022-01-25T13:18:07.292084Z","iopub.status.idle":"2022-01-25T13:18:07.296866Z","shell.execute_reply.started":"2022-01-25T13:18:07.292025Z","shell.execute_reply":"2022-01-25T13:18:07.295542Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(\n#     train_dataset,\n#     validation_data=validation_dataset,\n#     epochs=2\n# )","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:18:07.297897Z","iopub.execute_input":"2022-01-25T13:18:07.298891Z","iopub.status.idle":"2022-01-25T13:18:07.305258Z","shell.execute_reply.started":"2022-01-25T13:18:07.298855Z","shell.execute_reply":"2022-01-25T13:18:07.304525Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# custom training loop \n## update at each train step\n## reset at the end of each batch\n\nimport time\n## defining a optimizer \noptimizer= tf.keras.optimizers.Adam(lr=2e-5)\n\n## defining loss function \nloss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n# ## mean loss define\ntrain_loss=tf.keras.metrics.Mean(name=\"train_loss\")\nvalidation_loss=tf.keras.metrics.Mean(name=\"validation_loss\")\n\nbest_validation_loss=tf.keras.metrics.Mean(name=\"best_validation_loss\")\n\n# Metric\n## dfining the accuracy metric to track our model accuracy.Here for 6 class we \n## have to declare 2d darray of row 6\ntrain_acc_metric=[tf.keras.metrics.CategoricalAccuracy() for i in range(len(label_cols))]\n\nval_acc_metric=[tf.keras.metrics.CategoricalAccuracy() for i in range(len(label_cols))]\n\n# actually from logits denoting the probability from our custom model layed for each label.It is being fetched before the softmax layer to calculate loss between actual and predicted\n\nbatch_size=32\nEPOCH=2\ntrain_dataset_size=60000\nvalidation_dataset_size=15000\n\n@tf.function\ndef train_step(model,x_train,label):\n    # Gradiane tape actually records the operation run in forward step\n    with tf.GradientTape() as tape:\n        #caluculate logits for comparison\n        logits_prob=model(x_train,training=True)\n        # calculate loss value \n        loss_value=loss_fn(label,logits_prob)\n    #calculate gradient of trainable variables against the loss\n    gradients=tape.gradient(loss_value,model.trainable_weights)\n    # update the gradient according to gradient descent\n    optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n    # update the mean train ing loss\n    train_loss(loss_value)\n    # update accuracy metric for each of the 6 classes \n    for i,auc in enumerate(train_acc_metric):\n        auc.update_state(label[:,i],logits_prob[:,i])\n    return loss_value\n\n@tf.function\ndef validation_step(model,x_validation,label):\n    with tf.GradientTape() as tape:\n        validation_logit_prob=model(x_validation,training=False)\n        valid_loss=loss_fn(label,validation_logit_prob)\n        validation_loss(valid_loss)\n        for i,auc in enumerate(val_acc_metric):\n            auc.update_state(label[:,i],validation_logit_prob[:,i]) \n\ndef train_model(model,train_dataset,validation_dataset):\n    for epoch in range(EPOCHS):\n        print('\\n Epoch No %d\\n' % (epoch,))\n\n        ### training part ###\n        for step,(x_batch_train,labels) in enumerate(tqdm(train_dataset)):\n            training_loss=train_step(model,x_batch_train,labels)\n            \n            #log result at every 200 batches\n            if step%200==0:\n                print(f'\\nTrain Step: {epoch}, Loss: {train_loss.result()}')\n#                 print(\"Trainng loss at %d batch of data: %.4f\"%(step,float(training_loss)))\n                # training accuracy metric at end\n                for i, label_name in enumerate(label_cols):\n                    print(f\"{label_name} roc_auc {train_acc_metric[i].result()}\")\n                    # reset the accuracy metric after every epoch\n                    train_acc_metric[i].reset_states()\n            \n#         training_accuracy=train_acc_metric.result()\n#         print(\"\\nTraining accuracy after %d epoch : %.4f\"%(epoch,training_accuracy))\n#         train_acc_metric.reset_states()\n        \n        \n        ### validation part ###\n        for step,(x_batch_val,labels) in enumerate(tqdm(validation_dataset)):\n            validation_step(model,x_batch_val,labels)\n        print(f'\\n Validation Step: {epoch}, Loss: {validation_loss.result()}')\n        ## save best validate model weight\n#         if best_validation_loss<validation_loss:\n#             best_validation_loss=validation_loss\n#             model.save_weights('/kaggle/working/my_checkpoint')\n        for i, label_name in enumerate(label_cols):\n            print(f\"{label_name} roc_auc {val_acc_metric[i].result()}\") \n            val_acc_metric[i].reset_states()\n#         validation_acc=val_acc_metric.result()\n#         val_acc_metric.reset_states()\n#         print(\"\\n validation accuracy : %4.f\"%(validation_acc))\n\ntrain_model(model,train_dataset,validation_dataset)\nmodel.save(\"my_custom_train_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:18:07.308370Z","iopub.execute_input":"2022-01-25T13:18:07.308573Z","iopub.status.idle":"2022-01-25T13:26:11.861598Z","shell.execute_reply.started":"2022-01-25T13:18:07.308551Z","shell.execute_reply":"2022-01-25T13:26:11.860922Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\n Epoch No 0\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/955 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7c7beedf48480fb6d529bc346f82ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:4847: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n  '\"`categorical_crossentropy` received `from_logits=True`, but '\n2022-01-25 13:18:09.742846: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-01-25 13:18:11.020352: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Step: 0, Loss: 2.527096748352051\ntoxic roc_auc 0.0\nsevere_toxic roc_auc 0.0\nobscene roc_auc 0.0\nthreat roc_auc 0.0\ninsult roc_auc 0.0\nidentity_hate roc_auc 0.0\npositive roc_auc 0.0\n\nTrain Step: 0, Loss: 2.545086622238159\ntoxic roc_auc 0.02500000037252903\nsevere_toxic roc_auc 0.054999999701976776\nobscene roc_auc 0.08500000089406967\nthreat roc_auc 0.004999999888241291\ninsult roc_auc 0.029999999329447746\nidentity_hate roc_auc 0.03500000014901161\npositive roc_auc 0.054999999701976776\n\nTrain Step: 0, Loss: 2.34875750541687\ntoxic roc_auc 0.0949999988079071\nsevere_toxic roc_auc 0.014999999664723873\nobscene roc_auc 0.08500000089406967\nthreat roc_auc 0.03500000014901161\ninsult roc_auc 0.07000000029802322\nidentity_hate roc_auc 0.029999999329447746\npositive roc_auc 0.05000000074505806\n\nTrain Step: 0, Loss: 2.2482175827026367\ntoxic roc_auc 0.07500000298023224\nsevere_toxic roc_auc 0.05999999865889549\nobscene roc_auc 0.10499999672174454\nthreat roc_auc 0.014999999664723873\ninsult roc_auc 0.05000000074505806\nidentity_hate roc_auc 0.029999999329447746\npositive roc_auc 0.04500000178813934\n\nTrain Step: 0, Loss: 2.201246976852417\ntoxic roc_auc 0.0949999988079071\nsevere_toxic roc_auc 0.029999999329447746\nobscene roc_auc 0.06499999761581421\nthreat roc_auc 0.029999999329447746\ninsult roc_auc 0.05999999865889549\nidentity_hate roc_auc 0.029999999329447746\npositive roc_auc 0.06499999761581421\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d71b3ed2a3d4aaba48ca7decb135b6c"}},"metadata":{}},{"name":"stdout","text":"\n Validation Step: 0, Loss: 2.058198928833008\ntoxic roc_auc 0.07547169923782349\nsevere_toxic roc_auc 0.03773584961891174\nobscene roc_auc 0.06603773683309555\nthreat roc_auc 0.03773584961891174\ninsult roc_auc 0.03773584961891174\nidentity_hate roc_auc 0.07547169923782349\npositive roc_auc 0.04716981202363968\n\n Epoch No 1\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/955 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bfb5aa86cd44a72bb05692f3c0be7bf"}},"metadata":{}},{"name":"stdout","text":"\nTrain Step: 1, Loss: 2.188086748123169\ntoxic roc_auc 0.03870967775583267\nsevere_toxic roc_auc 0.032258063554763794\nobscene roc_auc 0.09677419066429138\nthreat roc_auc 0.019354838877916336\ninsult roc_auc 0.09677419066429138\nidentity_hate roc_auc 0.025806451216340065\npositive roc_auc 0.05161290243268013\n\nTrain Step: 1, Loss: 2.1674139499664307\ntoxic roc_auc 0.05000000074505806\nsevere_toxic roc_auc 0.05999999865889549\nobscene roc_auc 0.09000000357627869\nthreat roc_auc 0.02500000037252903\ninsult roc_auc 0.04500000178813934\nidentity_hate roc_auc 0.04500000178813934\npositive roc_auc 0.04500000178813934\n\nTrain Step: 1, Loss: 2.1630208492279053\ntoxic roc_auc 0.06499999761581421\nsevere_toxic roc_auc 0.05000000074505806\nobscene roc_auc 0.07500000298023224\nthreat roc_auc 0.014999999664723873\ninsult roc_auc 0.05999999865889549\nidentity_hate roc_auc 0.029999999329447746\npositive roc_auc 0.05999999865889549\n\nTrain Step: 1, Loss: 2.1619269847869873\ntoxic roc_auc 0.07999999821186066\nsevere_toxic roc_auc 0.07000000029802322\nobscene roc_auc 0.10000000149011612\nthreat roc_auc 0.04500000178813934\ninsult roc_auc 0.04500000178813934\nidentity_hate roc_auc 0.03500000014901161\npositive roc_auc 0.019999999552965164\n\nTrain Step: 1, Loss: 2.169426441192627\ntoxic roc_auc 0.07000000029802322\nsevere_toxic roc_auc 0.02500000037252903\nobscene roc_auc 0.08500000089406967\nthreat roc_auc 0.019999999552965164\ninsult roc_auc 0.05999999865889549\nidentity_hate roc_auc 0.009999999776482582\npositive roc_auc 0.054999999701976776\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/106 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fabd7c82d3146baa5f41a691bc94605"}},"metadata":{}},{"name":"stdout","text":"\n Validation Step: 1, Loss: 2.132277488708496\ntoxic roc_auc 0.06603773683309555\nsevere_toxic roc_auc 0.03773584961891174\nobscene roc_auc 0.08490566164255142\nthreat roc_auc 0.01886792480945587\ninsult roc_auc 0.056603774428367615\nidentity_hate roc_auc 0.07547169923782349\npositive roc_auc 0.06603773683309555\n","output_type":"stream"}]},{"cell_type":"code","source":"# from keras.models import load_model\n# model=load_model('../input/mymodel/my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:11.862802Z","iopub.execute_input":"2022-01-25T13:26:11.863042Z","iopub.status.idle":"2022-01-25T13:26:11.866603Z","shell.execute_reply.started":"2022-01-25T13:26:11.863008Z","shell.execute_reply":"2022-01-25T13:26:11.865930Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"s4 = '''Your code looks like it's undecided about whether it's data or elementdata. I've assumed it's simply a typo.'''\ns5=\"In hindsight, I do apologize for my previous statement.\"\ns6=\"mother fucker bitch!!\"\nsentence_pairs = np.array([s6])\ntest_data = BertSemanticDataGenerator(\n        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n    )\n\npro=model.predict(test_data) \nprint(np.asarray(pro))\nprint(label_cols[np.argmax(pro)])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:11.867925Z","iopub.execute_input":"2022-01-25T13:26:11.868384Z","iopub.status.idle":"2022-01-25T13:26:16.067541Z","shell.execute_reply.started":"2022-01-25T13:26:11.868350Z","shell.execute_reply":"2022-01-25T13:26:16.065907Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[[5.5961210e-01 6.6855957e-04 2.8777421e-01 1.1974039e-05 1.5119466e-01\n  8.7502951e-05 6.5101415e-04]]\ntoxic\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading the pre-defined bert model weights\n# bert_model.Trainable=True\n\n# train_dataset=BertSemanticDataGenerator(train_inputs,train_labels,shuffle=True)\n# validation_dataset=BertSemanticDataGenerator(validation_inputs,validation_labels,shuffle=False)\n\n# trained_history = model.fit(\n#     train_dataset,\n#     validation_data=validation_dataset,\n#     epochs=2\n# )","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:16.068995Z","iopub.execute_input":"2022-01-25T13:26:16.069260Z","iopub.status.idle":"2022-01-25T13:26:16.075331Z","shell.execute_reply.started":"2022-01-25T13:26:16.069225Z","shell.execute_reply":"2022-01-25T13:26:16.074633Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"submission_df=pd.read_csv(\"./sample_submission.csv\",index_col='id')\ntest_df=pd.read_csv(\"./test.csv\")\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate','positive']\nconditions = [\n    (submission_df['toxic']==0.5)&\n    (submission_df['severe_toxic']==0.5) & (submission_df['obscene']==0.5)&\n    (submission_df['threat']==0.5) & (submission_df['insult']==0.5)&\n    (submission_df['identity_hate']==0.5)\n    ]\nvalues = [0.5] \nsubmission_df['positive']=np.select(conditions,values)\n\nprint(submission_df.head())\nprint(test_df.head())\n\n\ntest_bert_op=BertSemanticDataGenerator(test_df['comment_text'],None,include_targets=False,shuffle=True)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:16.076695Z","iopub.execute_input":"2022-01-25T13:26:16.077204Z","iopub.status.idle":"2022-01-25T13:26:20.155717Z","shell.execute_reply.started":"2022-01-25T13:26:16.077002Z","shell.execute_reply":"2022-01-25T13:26:20.154904Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"                  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\nid                                                                              \n00001cee341fdb12    0.5           0.5      0.5     0.5     0.5            0.5   \n0000247867823ef7    0.5           0.5      0.5     0.5     0.5            0.5   \n00013b17ad220c46    0.5           0.5      0.5     0.5     0.5            0.5   \n00017563c3f7919a    0.5           0.5      0.5     0.5     0.5            0.5   \n00017695ad8997eb    0.5           0.5      0.5     0.5     0.5            0.5   \n\n                  positive  \nid                          \n00001cee341fdb12       0.5  \n0000247867823ef7       0.5  \n00013b17ad220c46       0.5  \n00017563c3f7919a       0.5  \n00017695ad8997eb       0.5  \n                 id                                       comment_text\n0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n3  00017563c3f7919a  :If you have a look back at the source, the in...\n4  00017695ad8997eb          I don't anonymously edit articles at all.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\nid                                                                              \n00001cee341fdb12    0.5           0.5      0.5     0.5     0.5            0.5   \n0000247867823ef7    0.5           0.5      0.5     0.5     0.5            0.5   \n00013b17ad220c46    0.5           0.5      0.5     0.5     0.5            0.5   \n00017563c3f7919a    0.5           0.5      0.5     0.5     0.5            0.5   \n00017695ad8997eb    0.5           0.5      0.5     0.5     0.5            0.5   \n...                 ...           ...      ...     ...     ...            ...   \nfffcd0960ee309b5    0.5           0.5      0.5     0.5     0.5            0.5   \nfffd7a9a6eb32c16    0.5           0.5      0.5     0.5     0.5            0.5   \nfffda9e8d6fafa9e    0.5           0.5      0.5     0.5     0.5            0.5   \nfffe8f1340a79fc2    0.5           0.5      0.5     0.5     0.5            0.5   \nffffce3fb183ee80    0.5           0.5      0.5     0.5     0.5            0.5   \n\n                  positive  \nid                          \n00001cee341fdb12       0.5  \n0000247867823ef7       0.5  \n00013b17ad220c46       0.5  \n00017563c3f7919a       0.5  \n00017695ad8997eb       0.5  \n...                    ...  \nfffcd0960ee309b5       0.5  \nfffd7a9a6eb32c16       0.5  \nfffda9e8d6fafa9e       0.5  \nfffe8f1340a79fc2       0.5  \nffffce3fb183ee80       0.5  \n\n[153164 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>positive</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00001cee341fdb12</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>0000247867823ef7</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00013b17ad220c46</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00017563c3f7919a</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00017695ad8997eb</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>fffcd0960ee309b5</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffd7a9a6eb32c16</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffda9e8d6fafa9e</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffe8f1340a79fc2</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ffffce3fb183ee80</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>153164 rows  7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i,sen in enumerate(tqdm(test_bert_op)):\n    sample_ids = test_df.iloc[i*32:(i+1)*32]['id'] \n    pred=model.predict(sen)\n    submission_df.loc[sample_ids, label_cols] = pred ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:20.156813Z","iopub.execute_input":"2022-01-25T13:26:20.157070Z","iopub.status.idle":"2022-01-25T13:26:29.804499Z","shell.execute_reply.started":"2022-01-25T13:26:20.157019Z","shell.execute_reply":"2022-01-25T13:26:29.802887Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4786 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54745e12df924f0e8646c8a2d5db4be2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/3960142976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_bert_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msample_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_34/1699009433.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m         )   \n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         )\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             )\n\u001b[1;32m    553\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         )\n\u001b[1;32m    379\u001b[0m         attention_output = self.dense_output(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[0;31m# (5) False (treating the layer as if it's in inference)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     args, kwargs, training_mode = self._set_training_mode(\n\u001b[0;32m-> 1005\u001b[0;31m         args, kwargs, call_context)\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;31m# Losses are cleared for all sublayers on the outermost `Layer.call`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_training_mode\u001b[0;34m(self, args, kwargs, call_context)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;31m# (1) `training` was passed to this `Layer.call`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_arg_was_passed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0mtraining_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_call_arg_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0;31m# If no `training` arg was passed, or `None` was explicitly passed,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_call_arg_was_passed\u001b[0;34m(self, arg_name, args, kwargs, inputs_in_args)\u001b[0m\n\u001b[1;32m   2531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_arg_was_passed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_in_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m     \u001b[0;31m# Performance optimization: do no work in most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:29.805532Z","iopub.status.idle":"2022-01-25T13:26:29.806424Z","shell.execute_reply.started":"2022-01-25T13:26:29.806182Z","shell.execute_reply":"2022-01-25T13:26:29.806206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_ids = test_df.iloc[0*32:(0+1)*32]['id'] \n# print(sample_ids)\n# submission_df.loc[sample_ids]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T13:26:29.807491Z","iopub.status.idle":"2022-01-25T13:26:29.808368Z","shell.execute_reply.started":"2022-01-25T13:26:29.808127Z","shell.execute_reply":"2022-01-25T13:26:29.808152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(bert_op)","metadata":{"_uuid":"8959229a-8e2d-4b3b-aac2-0fb6ce9a033d","_cell_guid":"54912915-4e18-4d75-91e8-026f9ce2e866","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:26:29.809381Z","iopub.status.idle":"2022-01-25T13:26:29.809899Z","shell.execute_reply.started":"2022-01-25T13:26:29.809670Z","shell.execute_reply":"2022-01-25T13:26:29.809693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # creating batched dataset\n# epochs=2\n# def create_batch_dataset(data,epochs=epochs,batch_size=batch_size,buffer_size=1000,train=True):\n#     dataset=tf.data.Dataset.from_tensor_slices(data)\n# #     print(dataset.as_numpy_iterator())\n#     if train:\n#         dataset=dataset.shuffle(buffer_size=buffer_size)\n#         # uses for shuffling the dataset.Select the first buffer_size element from dataset\n#     dataset=dataset.repeat(epochs)\n#     # just repeat the whole dataset\n#     dataset=dataset.batch(batch_size=batch_size)\n#     # devide the whole dataset into batch size and create an array of array\n#     if train:\n#         dataset=dataset.prefetch(1)\n#     #     It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two \n#     # elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 \n#     # batches, of 20 examples each).\n#     return dataset\n# train_dataset=create_batch_dataset((train_inputs,train_masks,train_labels),train=True)\n# validation_dataset=create_batch_dataset((validation_inputs,validation_masks,validation_labels),train=True)","metadata":{"_uuid":"d627f4cb-eafd-4f52-99d1-cacead47c1ca","_cell_guid":"0af7aedf-d747-4590-bec8-37a35f99eadb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:26:29.811291Z","iopub.status.idle":"2022-01-25T13:26:29.812075Z","shell.execute_reply.started":"2022-01-25T13:26:29.811819Z","shell.execute_reply":"2022-01-25T13:26:29.811844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/nkaenzig/bert-tensorflow-2-huggingface-transformers\n# https://www.kaggle.com/satyamkryadav/bert-model-96-77/notebook\n# https://github.com/tensorflow/models/blob/master/official/nlp/docs/tfhub.md","metadata":{"_uuid":"cf97dec3-abcc-41fb-92d7-bfa598eacba0","_cell_guid":"0d34a9f6-e683-4261-b26e-d5e31d2ef1e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-25T13:26:29.813378Z","iopub.status.idle":"2022-01-25T13:26:29.814264Z","shell.execute_reply.started":"2022-01-25T13:26:29.814011Z","shell.execute_reply":"2022-01-25T13:26:29.814035Z"},"trusted":true},"execution_count":null,"outputs":[]}]}