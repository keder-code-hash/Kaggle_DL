{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! unzip ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip \n! unzip ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip","metadata":{"_uuid":"0d89fec7-5d44-4336-9da5-469346fa2def","_cell_guid":"b5e152ff-6613-4ecf-a299-d475fca64685","execution":{"iopub.status.busy":"2022-01-24T09:20:53.069961Z","iopub.execute_input":"2022-01-24T09:20:53.070274Z","iopub.status.idle":"2022-01-24T09:20:57.566332Z","shell.execute_reply.started":"2022-01-24T09:20:53.070186Z","shell.execute_reply":"2022-01-24T09:20:57.565428Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Archive:  ../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n  inflating: train.csv               \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n  inflating: test_labels.csv         \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n  inflating: sample_submission.csv   \nArchive:  ../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n  inflating: test.csv                \n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install transformers \n# save the best weight ,means less loss valued trained batch \n# do some warm up step initially to make it more effiecient","metadata":{"_uuid":"a399aa52-641d-4b0b-ae94-428c6c4e20ff","_cell_guid":"76f4bbc5-95f6-4206-9caa-51d8fbd1b46b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:20:57.569032Z","iopub.execute_input":"2022-01-24T09:20:57.569736Z","iopub.status.idle":"2022-01-24T09:21:06.499620Z","shell.execute_reply.started":"2022-01-24T09:20:57.569677Z","shell.execute_reply":"2022-01-24T09:21:06.498761Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport transformers\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"262ea2b4-8965-457a-ac3f-36f3956394aa","_cell_guid":"f6f21706-c522-41f0-8eee-ec41acbad32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:21:06.501221Z","iopub.execute_input":"2022-01-24T09:21:06.501493Z","iopub.status.idle":"2022-01-24T09:21:12.294712Z","shell.execute_reply.started":"2022-01-24T09:21:06.501456Z","shell.execute_reply":"2022-01-24T09:21:12.293902Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\") \nbert_model.trainable = False","metadata":{"_uuid":"6bdfa15e-a5d6-4c58-b132-4e686af50782","_cell_guid":"b49e404e-c101-479b-9c40-39d581a7c7e6","execution":{"iopub.status.busy":"2022-01-24T09:21:12.296119Z","iopub.execute_input":"2022-01-24T09:21:12.296410Z","iopub.status.idle":"2022-01-24T09:21:46.933182Z","shell.execute_reply.started":"2022-01-24T09:21:12.296375Z","shell.execute_reply":"2022-01-24T09:21:46.932399Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181d1e8b60464d1f9726aef0025f5cda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd11bb617614a1798488467579bda50"}},"metadata":{}},{"name":"stderr","text":"2022-01-24 09:21:39.739930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:39.740946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:39.741632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:39.742668: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-01-24 09:21:39.743666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:39.744306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:39.744946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:44.494427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:44.495239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:44.495883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-01-24 09:21:44.496445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14959 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nSome layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=32\nmax_len=128\nEPOCHS=2","metadata":{"_uuid":"0a70ea60-c055-442d-a17b-92aa31a13d59","_cell_guid":"57e0530c-53c6-4440-8074-c165b041a7c5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:21:46.935382Z","iopub.execute_input":"2022-01-24T09:21:46.935786Z","iopub.status.idle":"2022-01-24T09:21:46.940407Z","shell.execute_reply.started":"2022-01-24T09:21:46.935748Z","shell.execute_reply":"2022-01-24T09:21:46.939700Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"./train.csv\") ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:46.941440Z","iopub.execute_input":"2022-01-24T09:21:46.942092Z","iopub.status.idle":"2022-01-24T09:21:47.818510Z","shell.execute_reply.started":"2022-01-24T09:21:46.942056Z","shell.execute_reply":"2022-01-24T09:21:47.817759Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# count the individual data\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] \npositive_comment=data[data[label_cols].sum(axis=1)==0]\ntoxic_comment=data[data[label_cols].sum(axis=1)>0]\nno_value=data[data[label_cols].sum(axis=1)=='']\n\n# print(len(positive_comment)) #143346\n# print(len(toxic_comment))# 16225\n# print(len(no_value))# 16225\n\n# random samling from positve commnet to tkae out of 14000 comment\n\n# toxic_comment=data[data['toxic']==1]\n# toxic_comment.shape\n## drop some toxic comment for better prediction\n\n# purely toxic\nconditions = [\n    (toxic_comment['toxic']==1)&\n    (toxic_comment['severe_toxic']==0) & (toxic_comment['obscene']==0)&\n    (toxic_comment['threat']==0) & (toxic_comment['insult']==0)&\n    (toxic_comment['identity_hate']==0)\n    ]\npurely_toxic=toxic_comment[conditions[0]]\nprint(purely_toxic.shape)\npurely_toxic.sample(frac = 1)\n# mixed toxic\nmixed_toxic=toxic_comment[toxic_comment['toxic']==1]\nprint(mixed_toxic.shape)\n\n# drop pure toxic\ntoxic_comment.drop(purely_toxic.index,inplace=True)\n\ndata=pd.concat([\n    toxic_comment,\n    purely_toxic.sample(n=700),\n    positive_comment.sample(n=30_000)\n])\n\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:47.819706Z","iopub.execute_input":"2022-01-24T09:21:47.819953Z","iopub.status.idle":"2022-01-24T09:21:47.900765Z","shell.execute_reply.started":"2022-01-24T09:21:47.819921Z","shell.execute_reply":"2022-01-24T09:21:47.899990Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(5666, 8)\n(15294, 8)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(41259, 8)"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nconditions = [\n    (data['toxic']==1)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\ntoxic_comment=data[conditions[0]]\n\nconditions1 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==1) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nsevere_toxic_comment=data[conditions1[0]]\n\nconditions2 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==1)&\n    (data['identity_hate']==0)\n    ]\ninsult_comment=data[conditions2[0]]\n\nconditions3 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==1)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nobscene_comment=data[conditions3[0]]\n\nconditions4 = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==1) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nthreat_comment=data[conditions4[0]]\n\n\nlabel_bar = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult']\nlabel_data=[toxic_comment.shape[0],severe_toxic_comment.shape[0],obscene_comment.shape[0],threat_comment.shape[0],insult_comment.shape[0]]\n\nfig=plt.figure(figsize=(10,5)) \nplt.bar(label_bar,label_data,color=\"red\",width=0.3)\nplt.xlabel(\"Comment Sense\")\nplt.ylabel(\"count of Sense\")\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:47.902157Z","iopub.execute_input":"2022-01-24T09:21:47.902935Z","iopub.status.idle":"2022-01-24T09:21:48.128402Z","shell.execute_reply.started":"2022-01-24T09:21:47.902896Z","shell.execute_reply":"2022-01-24T09:21:48.127680Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# add up a column positive\nconditions = [\n    (data['toxic']==0)&\n    (data['severe_toxic']==0) & (data['obscene']==0)&\n    (data['threat']==0) & (data['insult']==0)&\n    (data['identity_hate']==0)\n    ]\nvalues = [1]\n\n# data['positive']=np.where(data['toxic']==0 and data['severe_toxic']==0 and  and  and  and ,1,0)\ndata['positive']=np.select(conditions,values)\n\nlabel_cols.append(\"positive\")\n\nprint(data.shape)\npositive_comment=data[data[label_cols].sum(axis=1)==1]\nprint(len(positive_comment))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:48.129790Z","iopub.execute_input":"2022-01-24T09:21:48.130221Z","iopub.status.idle":"2022-01-24T09:21:48.158909Z","shell.execute_reply.started":"2022-01-24T09:21:48.130182Z","shell.execute_reply":"2022-01-24T09:21:48.158190Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(41259, 9)\n31394\n","output_type":"stream"}]},{"cell_type":"code","source":"data[\"comment_text\"]=data[\"comment_text\"].map(lambda x:re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x))","metadata":{"_uuid":"172c050f-530a-4cb9-bfeb-644d1d05e6bb","_cell_guid":"4e553d8c-573a-4b6a-a593-d18eed422cd3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:21:48.161952Z","iopub.execute_input":"2022-01-24T09:21:48.162496Z","iopub.status.idle":"2022-01-24T09:21:52.481706Z","shell.execute_reply.started":"2022-01-24T09:21:48.162464Z","shell.execute_reply":"2022-01-24T09:21:52.480947Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# sense_count_pd=pd.DataFrame(data[label_cols].value_counts()) \n# sense_count_pd","metadata":{"_uuid":"acb671f4-2798-46d8-a568-1f0fd86dd624","_cell_guid":"f5302b70-2145-4634-87fa-67fff1e297de","execution":{"iopub.status.busy":"2022-01-24T09:21:52.482982Z","iopub.execute_input":"2022-01-24T09:21:52.483224Z","iopub.status.idle":"2022-01-24T09:21:52.489104Z","shell.execute_reply.started":"2022-01-24T09:21:52.483192Z","shell.execute_reply":"2022-01-24T09:21:52.488429Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"labels =  data[label_cols].values","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:52.490479Z","iopub.execute_input":"2022-01-24T09:21:52.490737Z","iopub.status.idle":"2022-01-24T09:21:52.500231Z","shell.execute_reply.started":"2022-01-24T09:21:52.490704Z","shell.execute_reply":"2022-01-24T09:21:52.499576Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:52.501850Z","iopub.execute_input":"2022-01-24T09:21:52.502038Z","iopub.status.idle":"2022-01-24T09:21:52.510692Z","shell.execute_reply.started":"2022-01-24T09:21:52.502016Z","shell.execute_reply":"2022-01-24T09:21:52.509920Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(41259, 7)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \ninput_sen=data[\"comment_text\"].values\n# print(input_sen)\ntrain_inputs,validation_inputs,train_labels,validation_labels=train_test_split(input_sen,labels,random_state=0,test_size=0.1) \n\n\nprint(train_inputs.shape)\nprint(train_labels.shape)\n\nprint(validation_inputs.shape)\nprint(validation_labels.shape)\n ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:52.513453Z","iopub.execute_input":"2022-01-24T09:21:52.515299Z","iopub.status.idle":"2022-01-24T09:21:53.082953Z","shell.execute_reply.started":"2022-01-24T09:21:52.515263Z","shell.execute_reply":"2022-01-24T09:21:53.082216Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(37133,)\n(37133, 7)\n(4126,)\n(4126, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BertSemanticDataGenerator(tf.keras.utils.Sequence): \n    def __init__(\n        self,\n        sentence_pairs,\n        labels,\n        batch_size=batch_size,\n        shuffle=True,\n        include_targets=True,\n    ):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.include_targets = include_targets\n         \n        \n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.indexes = np.arange(len(self.sentence_pairs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch.\n        return len(self.sentence_pairs) // self.batch_size\n\n    def __getitem__(self, idx):\n        # Retrieves the batch of index.\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        sentence_pairs = self.sentence_pairs[indexes]\n\n        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n        # encoded together and separated by [SEP] token.\n        encoded = self.tokenizer.batch_encode_plus(\n            sentence_pairs.tolist(),\n            add_special_tokens=True,\n            max_length=128,\n            return_attention_mask=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_tensors=\"tf\",\n        )   \n\n        bert_output = bert_model(**encoded)\n        \n        sequence_output = bert_output.last_hidden_state \n         \n        if self.include_targets:\n            labels = np.array(self.labels[indexes], dtype=\"int32\")\n            return sequence_output, labels\n        else:\n            return sequence_output\n\n    def on_epoch_end(self): \n        if self.shuffle:\n            np.random.RandomState(42).shuffle(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:21:53.084352Z","iopub.execute_input":"2022-01-24T09:21:53.084753Z","iopub.status.idle":"2022-01-24T09:21:53.095871Z","shell.execute_reply.started":"2022-01-24T09:21:53.084719Z","shell.execute_reply":"2022-01-24T09:21:53.095149Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset=BertSemanticDataGenerator(train_inputs,train_labels,shuffle=True)\nvalidation_dataset=BertSemanticDataGenerator(validation_inputs,validation_labels,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:14.365739Z","iopub.execute_input":"2022-01-24T09:22:14.366470Z","iopub.status.idle":"2022-01-24T09:22:27.486678Z","shell.execute_reply.started":"2022-01-24T09:22:14.366429Z","shell.execute_reply":"2022-01-24T09:22:27.485834Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_layer = tf.keras.layers.Input(shape=(128, 768), name=None)  \nflat=tf.keras.layers.Flatten()(input_layer) \noutput = tf.keras.layers.Dense(7, activation=\"softmax\")(flat)\nmodel = tf.keras.models.Model(inputs=input_layer, outputs=output)\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:32.275130Z","iopub.execute_input":"2022-01-24T09:22:32.275440Z","iopub.status.idle":"2022-01-24T09:22:32.311544Z","shell.execute_reply.started":"2022-01-24T09:22:32.275407Z","shell.execute_reply":"2022-01-24T09:22:32.310741Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 128, 768)]        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 98304)             0         \n_________________________________________________________________\ndense (Dense)                (None, 7)                 688135    \n=================================================================\nTotal params: 688,135\nTrainable params: 688,135\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.compile()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:06.147396Z","iopub.status.idle":"2022-01-24T09:22:06.148002Z","shell.execute_reply.started":"2022-01-24T09:22:06.147755Z","shell.execute_reply":"2022-01-24T09:22:06.147780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(\n#     train_dataset,\n#     validation_data=validation_dataset,\n#     epochs=2\n# )","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:06.149239Z","iopub.status.idle":"2022-01-24T09:22:06.149651Z","shell.execute_reply.started":"2022-01-24T09:22:06.149423Z","shell.execute_reply":"2022-01-24T09:22:06.149444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom training loop \n## update at each train step\n## reset at the end of each batch\n\nimport time\n## defining a optimizer \noptimizer= tf.keras.optimizers.Adam(lr=2e-5)\n\n## defining loss function \nloss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n# ## mean loss define\ntrain_loss=tf.keras.metrics.Mean(name=\"train_loss\")\nvalidation_loss=tf.keras.metrics.Mean(name=\"validation_loss\")\n\nbest_validation_loss=tf.keras.metrics.Mean(name=\"best_validation_loss\")\n\n# Metric\n## dfining the accuracy metric to track our model accuracy.Here for 6 class we \n## have to declare 2d darray of row 6\ntrain_acc_metric=[tf.keras.metrics.CategoricalAccuracy() for i in range(len(label_cols))]\n\nval_acc_metric=[tf.keras.metrics.CategoricalAccuracy() for i in range(len(label_cols))]\n\n# actually from logits denoting the probability from our custom model layed for each label.It is being fetched before the softmax layer to calculate loss between actual and predicted\n\nbatch_size=32\nEPOCH=2\ntrain_dataset_size=60000\nvalidation_dataset_size=15000\n\n@tf.function\ndef train_step(model,x_train,label):\n    # Gradiane tape actually records the operation run in forward step\n    with tf.GradientTape() as tape:\n        #caluculate logits for comparison\n        logits_prob=model(x_train,training=True)\n        # calculate loss value \n        loss_value=loss_fn(label,logits_prob)\n    #calculate gradient of trainable variables against the loss\n    gradients=tape.gradient(loss_value,model.trainable_weights)\n    # update the gradient according to gradient descent\n    optimizer.apply_gradients(zip(gradients,model.trainable_weights))\n    # update the mean train ing loss\n    train_loss(loss_value)\n    # update accuracy metric for each of the 6 classes \n    for i,auc in enumerate(train_acc_metric):\n        auc.update_state(label[:,i],logits_prob[:,i])\n    return loss_value\n\n@tf.function\ndef validation_step(model,x_validation,label):\n    with tf.GradientTape() as tape:\n        validation_logit_prob=model(x_validation,training=False)\n        valid_loss=loss_fn(label,validation_logit_prob)\n        validation_loss(valid_loss)\n        for i,auc in enumerate(val_acc_metric):\n            auc.update_state(label[:,i],validation_logit_prob[:,i]) \n\ndef train_model(model,train_dataset,validation_dataset):\n    for epoch in range(EPOCHS):\n        print('\\n Epoch No %d\\n' % (epoch,))\n\n        ### training part ###\n        for step,(x_batch_train,labels) in enumerate(tqdm(train_dataset)):\n            training_loss=train_step(model,x_batch_train,labels)\n            \n            #log result at every 200 batches\n            if step%200==0:\n                print(f'\\nTrain Step: {epoch}, Loss: {train_loss.result()}')\n#                 print(\"Trainng loss at %d batch of data: %.4f\"%(step,float(training_loss)))\n                # training accuracy metric at end\n                for i, label_name in enumerate(label_cols):\n                    print(f\"{label_name} roc_auc {train_acc_metric[i].result()}\")\n                    # reset the accuracy metric after every epoch\n                    train_acc_metric[i].reset_states()\n            \n#         training_accuracy=train_acc_metric.result()\n#         print(\"\\nTraining accuracy after %d epoch : %.4f\"%(epoch,training_accuracy))\n#         train_acc_metric.reset_states()\n        \n        \n        ### validation part ###\n        for step,(x_batch_val,labels) in enumerate(tqdm(validation_dataset)):\n            validation_step(model,x_batch_val,labels)\n        print(f'\\n Validation Step: {epoch}, Loss: {validation_loss.result()}')\n        ## save best validate model weight\n#         if best_validation_loss<validation_loss:\n#             best_validation_loss=validation_loss\n#             model.save_weights('/kaggle/working/my_checkpoint')\n        for i, label_name in enumerate(label_cols):\n            print(f\"{label_name} roc_auc {val_acc_metric[i].result()}\") \n            val_acc_metric[i].reset_states()\n#         validation_acc=val_acc_metric.result()\n#         val_acc_metric.reset_states()\n#         print(\"\\n validation accuracy : %4.f\"%(validation_acc))\n\ntrain_model(model,train_dataset,validation_dataset)\nmodel.save(\"my_custom_train_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:37.183876Z","iopub.execute_input":"2022-01-24T09:22:37.184194Z","iopub.status.idle":"2022-01-24T09:32:26.938609Z","shell.execute_reply.started":"2022-01-24T09:22:37.184160Z","shell.execute_reply":"2022-01-24T09:32:26.937889Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\n Epoch No 0\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"923dfca861cd4a10b767f5fd17245736"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/keras/backend.py:4847: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n  '\"`categorical_crossentropy` received `from_logits=True`, but '\n2022-01-24 09:22:37.962659: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Step: 0, Loss: 2.885316848754883\ntoxic roc_auc 0.0\nsevere_toxic roc_auc 0.0\nobscene roc_auc 0.0\nthreat roc_auc 0.0\ninsult roc_auc 0.0\nidentity_hate roc_auc 0.0\npositive roc_auc 0.0\n\nTrain Step: 0, Loss: 1.9412648677825928\ntoxic roc_auc 0.09000000357627869\nsevere_toxic roc_auc 0.03999999910593033\nobscene roc_auc 0.125\nthreat roc_auc 0.004999999888241291\ninsult roc_auc 0.10999999940395355\nidentity_hate roc_auc 0.06499999761581421\npositive roc_auc 0.05000000074505806\n\nTrain Step: 0, Loss: 2.1594204902648926\ntoxic roc_auc 0.10999999940395355\nsevere_toxic roc_auc 0.07500000298023224\nobscene roc_auc 0.10000000149011612\nthreat roc_auc 0.03500000014901161\ninsult roc_auc 0.125\nidentity_hate roc_auc 0.054999999701976776\npositive roc_auc 0.04500000178813934\n\nTrain Step: 0, Loss: 2.4766838550567627\ntoxic roc_auc 0.11500000208616257\nsevere_toxic roc_auc 0.07000000029802322\nobscene roc_auc 0.13500000536441803\nthreat roc_auc 0.04500000178813934\ninsult roc_auc 0.11999999731779099\nidentity_hate roc_auc 0.06499999761581421\npositive roc_auc 0.05999999865889549\n\nTrain Step: 0, Loss: 2.6989715099334717\ntoxic roc_auc 0.11500000208616257\nsevere_toxic roc_auc 0.05000000074505806\nobscene roc_auc 0.06499999761581421\nthreat roc_auc 0.04500000178813934\ninsult roc_auc 0.11500000208616257\nidentity_hate roc_auc 0.06499999761581421\npositive roc_auc 0.019999999552965164\n\nTrain Step: 0, Loss: 2.992439031600952\ntoxic roc_auc 0.11999999731779099\nsevere_toxic roc_auc 0.05999999865889549\nobscene roc_auc 0.11500000208616257\nthreat roc_auc 0.029999999329447746\ninsult roc_auc 0.13500000536441803\nidentity_hate roc_auc 0.03500000014901161\npositive roc_auc 0.054999999701976776\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11dd8cb2f6c24d6d87a2514595453444"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"\n Validation Step: 0, Loss: 6.057161808013916\ntoxic roc_auc 0.0546875\nsevere_toxic roc_auc 0.0625\nobscene roc_auc 0.1328125\nthreat roc_auc 0.03125\ninsult roc_auc 0.1953125\nidentity_hate roc_auc 0.0234375\npositive roc_auc 0.0234375\n\n Epoch No 1\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5520b3aabf32425d96e0cb728f52a782"}},"metadata":{}},{"name":"stdout","text":"\nTrain Step: 1, Loss: 3.288447856903076\ntoxic roc_auc 0.09375\nsevere_toxic roc_auc 0.06875000149011612\nobscene roc_auc 0.14374999701976776\nthreat roc_auc 0.03750000149011612\ninsult roc_auc 0.11249999701976776\nidentity_hate roc_auc 0.05000000074505806\npositive roc_auc 0.03750000149011612\n\nTrain Step: 1, Loss: 3.7563154697418213\ntoxic roc_auc 0.10999999940395355\nsevere_toxic roc_auc 0.054999999701976776\nobscene roc_auc 0.18000000715255737\nthreat roc_auc 0.09000000357627869\ninsult roc_auc 0.11500000208616257\nidentity_hate roc_auc 0.02500000037252903\npositive roc_auc 0.05000000074505806\n\nTrain Step: 1, Loss: 4.185359477996826\ntoxic roc_auc 0.10000000149011612\nsevere_toxic roc_auc 0.07500000298023224\nobscene roc_auc 0.125\nthreat roc_auc 0.33000001311302185\ninsult roc_auc 0.13500000536441803\nidentity_hate roc_auc 0.05000000074505806\npositive roc_auc 0.06499999761581421\n\nTrain Step: 1, Loss: 4.623937606811523\ntoxic roc_auc 0.125\nsevere_toxic roc_auc 0.07500000298023224\nobscene roc_auc 0.1599999964237213\nthreat roc_auc 0.5149999856948853\ninsult roc_auc 0.13500000536441803\nidentity_hate roc_auc 0.054999999701976776\npositive roc_auc 0.09000000357627869\n\nTrain Step: 1, Loss: 4.929274559020996\ntoxic roc_auc 0.125\nsevere_toxic roc_auc 0.03999999910593033\nobscene roc_auc 0.09000000357627869\nthreat roc_auc 0.7200000286102295\ninsult roc_auc 0.10999999940395355\nidentity_hate roc_auc 0.054999999701976776\npositive roc_auc 0.14000000059604645\n\nTrain Step: 1, Loss: 5.259110450744629\ntoxic roc_auc 0.11999999731779099\nsevere_toxic roc_auc 0.054999999701976776\nobscene roc_auc 0.125\nthreat roc_auc 0.7749999761581421\ninsult roc_auc 0.1550000011920929\nidentity_hate roc_auc 0.03999999910593033\npositive roc_auc 0.1850000023841858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/128 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f4d44f4700419a9dac5e8025ef85ed"}},"metadata":{}},{"name":"stdout","text":"\n Validation Step: 1, Loss: 8.686864852905273\ntoxic roc_auc 0.0703125\nsevere_toxic roc_auc 0.046875\nobscene roc_auc 0.125\nthreat roc_auc 0.6953125\ninsult roc_auc 0.15625\nidentity_hate roc_auc 0.0234375\npositive roc_auc 0.2265625\n","output_type":"stream"}]},{"cell_type":"code","source":"# from keras.models import load_model\n# model=load_model('../input/mymodel/my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:06.152889Z","iopub.status.idle":"2022-01-24T09:22:06.153494Z","shell.execute_reply.started":"2022-01-24T09:22:06.153251Z","shell.execute_reply":"2022-01-24T09:22:06.153276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s4 = '''Your code looks like it's undecided about whether it's data or elementdata. I've assumed it's simply a typo.'''\ns5=\"In hindsight, I do apologize for my previous statement.\"\ns6=\"you are a bitch.\"\nsentence_pairs = np.array([s4])\ntest_data = BertSemanticDataGenerator(\n        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n    )\n\npro=model.predict(test_data) \nprint(np.asarray(pro))\nprint(label_cols[np.argmax(pro)])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:49:33.831943Z","iopub.execute_input":"2022-01-24T09:49:33.832204Z","iopub.status.idle":"2022-01-24T09:49:40.654468Z","shell.execute_reply.started":"2022-01-24T09:49:33.832176Z","shell.execute_reply":"2022-01-24T09:49:40.653593Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"[[2.5708766e-10 0.0000000e+00 9.7222778e-11 0.0000000e+00 4.9823506e-11\n  3.1435211e-38 1.0000000e+00]]\npositive\n","output_type":"stream"}]},{"cell_type":"code","source":"# loading the pre-defined bert model weights\n# bert_model.Trainable=True\n\n# train_dataset=BertSemanticDataGenerator(train_inputs,train_labels,shuffle=True)\n# validation_dataset=BertSemanticDataGenerator(validation_inputs,validation_labels,shuffle=False)\n\n# trained_history = model.fit(\n#     train_dataset,\n#     validation_data=validation_dataset,\n#     epochs=2\n# )","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:06.157318Z","iopub.status.idle":"2022-01-24T09:22:06.158276Z","shell.execute_reply.started":"2022-01-24T09:22:06.157983Z","shell.execute_reply":"2022-01-24T09:22:06.158009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=pd.read_csv(\"./sample_submission.csv\",index_col='id')\ntest_df=pd.read_csv(\"./test.csv\")\nlabel_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate','positive']\nconditions = [\n    (submission_df['toxic']==0.5)&\n    (submission_df['severe_toxic']==0.5) & (submission_df['obscene']==0.5)&\n    (submission_df['threat']==0.5) & (submission_df['insult']==0.5)&\n    (submission_df['identity_hate']==0.5)\n    ]\nvalues = [0.5] \nsubmission_df['positive']=np.select(conditions,values)\n\nprint(submission_df.head())\nprint(test_df.head())\n\n\ntest_bert_op=BertSemanticDataGenerator(test_df['comment_text'],None,include_targets=False,shuffle=True)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:49:51.901945Z","iopub.execute_input":"2022-01-24T09:49:51.902231Z","iopub.status.idle":"2022-01-24T09:49:59.796152Z","shell.execute_reply.started":"2022-01-24T09:49:51.902199Z","shell.execute_reply":"2022-01-24T09:49:59.795458Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"                  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\nid                                                                              \n00001cee341fdb12    0.5           0.5      0.5     0.5     0.5            0.5   \n0000247867823ef7    0.5           0.5      0.5     0.5     0.5            0.5   \n00013b17ad220c46    0.5           0.5      0.5     0.5     0.5            0.5   \n00017563c3f7919a    0.5           0.5      0.5     0.5     0.5            0.5   \n00017695ad8997eb    0.5           0.5      0.5     0.5     0.5            0.5   \n\n                  positive  \nid                          \n00001cee341fdb12       0.5  \n0000247867823ef7       0.5  \n00013b17ad220c46       0.5  \n00017563c3f7919a       0.5  \n00017695ad8997eb       0.5  \n                 id                                       comment_text\n0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n3  00017563c3f7919a  :If you have a look back at the source, the in...\n4  00017695ad8997eb          I don't anonymously edit articles at all.\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"                  toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\nid                                                                              \n00001cee341fdb12    0.5           0.5      0.5     0.5     0.5            0.5   \n0000247867823ef7    0.5           0.5      0.5     0.5     0.5            0.5   \n00013b17ad220c46    0.5           0.5      0.5     0.5     0.5            0.5   \n00017563c3f7919a    0.5           0.5      0.5     0.5     0.5            0.5   \n00017695ad8997eb    0.5           0.5      0.5     0.5     0.5            0.5   \n...                 ...           ...      ...     ...     ...            ...   \nfffcd0960ee309b5    0.5           0.5      0.5     0.5     0.5            0.5   \nfffd7a9a6eb32c16    0.5           0.5      0.5     0.5     0.5            0.5   \nfffda9e8d6fafa9e    0.5           0.5      0.5     0.5     0.5            0.5   \nfffe8f1340a79fc2    0.5           0.5      0.5     0.5     0.5            0.5   \nffffce3fb183ee80    0.5           0.5      0.5     0.5     0.5            0.5   \n\n                  positive  \nid                          \n00001cee341fdb12       0.5  \n0000247867823ef7       0.5  \n00013b17ad220c46       0.5  \n00017563c3f7919a       0.5  \n00017695ad8997eb       0.5  \n...                    ...  \nfffcd0960ee309b5       0.5  \nfffd7a9a6eb32c16       0.5  \nfffda9e8d6fafa9e       0.5  \nfffe8f1340a79fc2       0.5  \nffffce3fb183ee80       0.5  \n\n[153164 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>positive</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00001cee341fdb12</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>0000247867823ef7</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00013b17ad220c46</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00017563c3f7919a</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>00017695ad8997eb</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>fffcd0960ee309b5</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffd7a9a6eb32c16</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffda9e8d6fafa9e</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>fffe8f1340a79fc2</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>ffffce3fb183ee80</th>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>153164 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i,sen in enumerate(tqdm(test_bert_op)):\n    sample_ids = test_df.iloc[i*32:(i+1)*32]['id'] \n    pred=model.predict(sen)\n    submission_df.loc[sample_ids, label_cols] = pred ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:50:00.691850Z","iopub.execute_input":"2022-01-24T09:50:00.692436Z","iopub.status.idle":"2022-01-24T10:11:09.257501Z","shell.execute_reply.started":"2022-01-24T09:50:00.692393Z","shell.execute_reply":"2022-01-24T10:11:09.256757Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4786 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f44499a77a4ba98a9f3855c2b8906e"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T10:12:25.178151Z","iopub.execute_input":"2022-01-24T10:12:25.178648Z","iopub.status.idle":"2022-01-24T10:12:27.292760Z","shell.execute_reply.started":"2022-01-24T10:12:25.178610Z","shell.execute_reply":"2022-01-24T10:12:27.292003Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# sample_ids = test_df.iloc[0*32:(0+1)*32]['id'] \n# print(sample_ids)\n# submission_df.loc[sample_ids]","metadata":{"execution":{"iopub.status.busy":"2022-01-24T09:22:06.165586Z","iopub.status.idle":"2022-01-24T09:22:06.166468Z","shell.execute_reply.started":"2022-01-24T09:22:06.166228Z","shell.execute_reply":"2022-01-24T09:22:06.166253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(bert_op)","metadata":{"_uuid":"8959229a-8e2d-4b3b-aac2-0fb6ce9a033d","_cell_guid":"54912915-4e18-4d75-91e8-026f9ce2e866","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:22:06.167791Z","iopub.status.idle":"2022-01-24T09:22:06.168704Z","shell.execute_reply.started":"2022-01-24T09:22:06.168441Z","shell.execute_reply":"2022-01-24T09:22:06.168466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # creating batched dataset\n# epochs=2\n# def create_batch_dataset(data,epochs=epochs,batch_size=batch_size,buffer_size=1000,train=True):\n#     dataset=tf.data.Dataset.from_tensor_slices(data)\n# #     print(dataset.as_numpy_iterator())\n#     if train:\n#         dataset=dataset.shuffle(buffer_size=buffer_size)\n#         # uses for shuffling the dataset.Select the first buffer_size element from dataset\n#     dataset=dataset.repeat(epochs)\n#     # just repeat the whole dataset\n#     dataset=dataset.batch(batch_size=batch_size)\n#     # devide the whole dataset into batch size and create an array of array\n#     if train:\n#         dataset=dataset.prefetch(1)\n#     #     It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two \n#     # elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 \n#     # batches, of 20 examples each).\n#     return dataset\n# train_dataset=create_batch_dataset((train_inputs,train_masks,train_labels),train=True)\n# validation_dataset=create_batch_dataset((validation_inputs,validation_masks,validation_labels),train=True)","metadata":{"_uuid":"d627f4cb-eafd-4f52-99d1-cacead47c1ca","_cell_guid":"0af7aedf-d747-4590-bec8-37a35f99eadb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:22:06.172571Z","iopub.status.idle":"2022-01-24T09:22:06.173641Z","shell.execute_reply.started":"2022-01-24T09:22:06.173262Z","shell.execute_reply":"2022-01-24T09:22:06.173312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/nkaenzig/bert-tensorflow-2-huggingface-transformers\n# https://www.kaggle.com/satyamkryadav/bert-model-96-77/notebook\n# https://github.com/tensorflow/models/blob/master/official/nlp/docs/tfhub.md","metadata":{"_uuid":"cf97dec3-abcc-41fb-92d7-bfa598eacba0","_cell_guid":"0d34a9f6-e683-4261-b26e-d5e31d2ef1e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-24T09:22:06.175354Z","iopub.status.idle":"2022-01-24T09:22:06.176491Z","shell.execute_reply.started":"2022-01-24T09:22:06.176211Z","shell.execute_reply":"2022-01-24T09:22:06.176241Z"},"trusted":true},"execution_count":null,"outputs":[]}]}