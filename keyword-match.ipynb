{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers ","metadata":{"id":"D6e6PitCbfZv","execution":{"iopub.status.busy":"2022-01-11T18:52:35.901588Z","iopub.execute_input":"2022-01-11T18:52:35.901950Z","iopub.status.idle":"2022-01-11T18:52:47.598317Z","shell.execute_reply.started":"2022-01-11T18:52:35.901858Z","shell.execute_reply":"2022-01-11T18:52:47.597445Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n     |████████████████████████████████| 78 kB 682 kB/s            \n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.12.5)\nRequirement already satisfied: tokenizers>=0.10.3 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.62.3)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.9.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.23.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.96)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.25.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (1.1.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (8.2.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (8.0.3)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=47f9214d658797f2878e2c27b04dd151bbe4863e525a3a1c4713e0e4ac283ada\n  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keybert","metadata":{"id":"tvi8uQ8JxZMa","execution":{"iopub.status.busy":"2022-01-11T18:52:47.600253Z","iopub.execute_input":"2022-01-11T18:52:47.600630Z","iopub.status.idle":"2022-01-11T18:52:58.001651Z","shell.execute_reply.started":"2022-01-11T18:52:47.600576Z","shell.execute_reply":"2022-01-11T18:52:58.000802Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting keybert\n  Downloading keybert-0.5.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: sentence-transformers>=0.3.8 in /opt/conda/lib/python3.7/site-packages (from keybert) (2.1.0)\nRequirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.7/site-packages (from keybert) (0.23.2)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.7/site-packages (from keybert) (1.19.5)\nCollecting rich>=10.4.0\n  Downloading rich-11.0.0-py3-none-any.whl (215 kB)\n     |████████████████████████████████| 215 kB 608 kB/s            \n\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (3.10.0.2)\nCollecting commonmark<0.10.0,>=0.9.0\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n     |████████████████████████████████| 51 kB 3.3 MB/s            \n\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (2.10.0)\nRequirement already satisfied: colorama<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from rich>=10.4.0->keybert) (0.4.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (1.7.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.2->keybert) (3.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (4.62.3)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.10.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (1.9.1)\nRequirement already satisfied: tokenizers>=0.10.3 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.10.3)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (3.2.4)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers>=0.3.8->keybert) (4.12.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.8.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.3.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (6.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.0.46)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.16.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (8.2.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.26.7)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (8.0.3)\nBuilding wheels for collected packages: keybert\n  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keybert: filename=keybert-0.5.0-py3-none-any.whl size=20491 sha256=34d09646f5555267eef38313b6423609acd0044e6a07c4c7821ef638f4181c82\n  Stored in directory: /root/.cache/pip/wheels/99/1f/3f/590d2997adbb2d0e1f82e8ee05d42d6910e92c3ed283015ff8\nSuccessfully built keybert\nInstalling collected packages: commonmark, rich, keybert\nSuccessfully installed commonmark-0.9.1 keybert-0.5.0 rich-11.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd   \nimport sklearn \nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics.pairwise import manhattan_distances\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom sklearn import metrics  \nfrom scipy.spatial import distance\nfrom sentence_transformers import SentenceTransformer \nfrom keybert import KeyBERT\nkw_model = KeyBERT()\nmodel = SentenceTransformer('distilbert-base-nli-mean-tokens')","metadata":{"id":"g1d74Bq1ntnI","execution":{"iopub.status.busy":"2022-01-11T18:52:58.003283Z","iopub.execute_input":"2022-01-11T18:52:58.003843Z","iopub.status.idle":"2022-01-11T18:53:42.543999Z","shell.execute_reply.started":"2022-01-11T18:52:58.003801Z","shell.execute_reply":"2022-01-11T18:53:42.543254Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c078a1b2b2dc4a79a037031d634004eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/10.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2cf408079a54bd4881950575e8ff2c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d75cc214f39342d38196e6302ec615eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62538ac2db7241c8b8dea39b6417e19f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a6e922aa5f842978878a60ce24bb27a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f62ccf9bfe84f1a87efa6d14d56a7f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e496c8284c4e39bf39ffd029a1cdc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2710bed46b2d4be59cdc771ed6dceac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188488069ebf42d9ab5674f59b737384"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0092dea0c916435a8b613d2ed2a99dd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1b9f16143bd496691b6fce15aa7cd5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84091f8ced9144adb61b5316c21235a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83f2becd83040059185b495ad5b6cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7b30ba9b68473f9fd8019a3e115e29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753d42e9dcc14ab59e9891cde6e01705"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/3.99k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6993d77b33ac4cafa1e2c83767dd01ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/550 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d84b671f00c1471bba25ffb70d28da5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a5895b478444596a2fbc6d151227d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09aaf54190a3423a8bc9b1088daed007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"debc04c9162744b98848e97e2bec0b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22aac50fe3b14160aaa557f04481e129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292ef4e0fa97410cb2117e94155433e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c727e5434ff4feea88e7a57391482a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/450 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57ef4a74a97408495fca5b1e5ce3cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc51cb7b532f44c29fa359876f7d7d17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767ff1baf977499e9726dc28cf15244b"}},"metadata":{}}]},{"cell_type":"code","source":"dataframe=pd.read_csv(\"../input/testdata/data.csv\")\ndataframe.shape","metadata":{"id":"TozJrMCTark0","execution":{"iopub.status.busy":"2022-01-11T18:54:12.940852Z","iopub.execute_input":"2022-01-11T18:54:12.941128Z","iopub.status.idle":"2022-01-11T18:54:12.961793Z","shell.execute_reply.started":"2022-01-11T18:54:12.941097Z","shell.execute_reply":"2022-01-11T18:54:12.961103Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(24, 4)"},"metadata":{}}]},{"cell_type":"code","source":"# standard_answer=dataframe['Questioner Answer'][6]\n# student_answer=dataframe['''Student's Answer'''][6] ","metadata":{"id":"3LTBSGOUkynH","execution":{"iopub.status.busy":"2022-01-11T18:53:42.979812Z","iopub.status.idle":"2022-01-11T18:53:42.980489Z","shell.execute_reply.started":"2022-01-11T18:53:42.980232Z","shell.execute_reply":"2022-01-11T18:53:42.980258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimilarityMetric:\n    def __init__(self,student_answer,standard_answer,st_ans,sn_ans,model=model) -> None:\n        self.student_answer=student_answer\n        self.standard_answer=standard_answer \n        self.st_ans=st_ans\n        self.sn_ans=sn_ans \n        self.embded_student_answer = model.encode(student_answer)\n        self.embded_standard_answer= model.encode(standard_answer)\n\n    def euclidian_dist(self): \n        dist=euclidean_distances(self.embded_standard_answer,self.embded_student_answer) \n        result=0.0\n        for d in dist: \n            result=min(d)\n        return result/dist.shape[0]\n    \n    def manhatten_dist(self):\n        dist=manhattan_distances( self.embded_standard_answer,self.embded_student_answer) \n        result=0.0\n        for d in dist: \n            result=min(d)\n        return result/dist.shape[0]\n#         return manhattan_distances( self.embded_standard_answer,self.embded_student_answer) \n\n    def cosine_similarity(self): \n        distances = cosine_similarity( self.embded_standard_answer,self.embded_student_answer)\n        result=0.0\n        for d in distances: \n            result=max(d)\n        return result/distances.shape[0] \n    \n    def Jaccard_Similarity(self): \n\n        words_doc1 = set(self.st_ans.lower().split()) \n        words_doc2 = set(self.sn_ans.lower().split())\n\n        intersection = words_doc1.intersection(words_doc2)\n\n        union = words_doc1.union(words_doc2)\n\n        return float(len(intersection)) / len(union)\n\n","metadata":{"id":"SH5IWT2Lb7e5","execution":{"iopub.status.busy":"2022-01-11T18:54:17.580296Z","iopub.execute_input":"2022-01-11T18:54:17.580708Z","iopub.status.idle":"2022-01-11T18:54:17.594588Z","shell.execute_reply.started":"2022-01-11T18:54:17.580673Z","shell.execute_reply":"2022-01-11T18:54:17.593442Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cosine_similar=[]\neuclid_dist=[]\nmanhatten_d=[]\njaccard_Similarity=[]\nstnd_ans=[]\nstud_ans=[]\n_id=[]\nactual_sentiments=[]\nfor i in range(dataframe.shape[0]):\n    standard_answer=dataframe['sentence1'][i]\n    student_answer=dataframe['sentence2'][i] \n    keywords_stnd = kw_model.extract_keywords([standard_answer], keyphrase_ngram_range=(1, 3), stop_words='english', use_mmr=True, diversity=0.3) \n    keywords_stud = kw_model.extract_keywords([student_answer], keyphrase_ngram_range=(1, 3), stop_words='english', use_mmr=True, diversity=0.3)\n    candidates_standard=[]\n    candidates_student=[]\n\n    for key,match in keywords_stnd[0]: \n      candidates_standard.append(key)\n    for key,match in keywords_stud[0]:\n      candidates_student.append(key) \n\n    sim_obj=SimilarityMetric(candidates_standard,candidates_student,standard_answer,student_answer)\n    \n    cosine_similar.append(sim_obj.cosine_similarity())\n    euclid_dist.append(sim_obj.euclidian_dist())\n    manhatten_d.append(sim_obj.manhatten_dist())\n    jaccard_Similarity.append(sim_obj.Jaccard_Similarity())\n    stnd_ans.append(standard_answer)\n    stud_ans.append(student_answer)\n    _id.append(i)\n    actual_sentiments.append(dataframe['label'][i])\ndict_sample = {'Id':_id,'Standard_Answer': stnd_ans, 'Student_Answer': stud_ans,'Actual Sentiment':actual_sentiments,'Cosine_Similarity': cosine_similar,'Euclidian_Distance':euclid_dist,'Manhatten_Distance':manhatten_d,'JaccardSimilarity':jaccard_Similarity,} \n     \ndf = pd.DataFrame(dict_sample)\n   \ndf.to_csv('KeywordTest.csv')\n    ","metadata":{"id":"vs4SKCWcogeQ","execution":{"iopub.status.busy":"2022-01-11T18:54:28.896101Z","iopub.execute_input":"2022-01-11T18:54:28.896706Z","iopub.status.idle":"2022-01-11T18:54:38.430694Z","shell.execute_reply.started":"2022-01-11T18:54:28.896666Z","shell.execute_reply":"2022-01-11T18:54:38.429958Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 399.84it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 311.13it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500fade823bf4d42a89ba27ef5d31eed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6289bf18013b4f4cbfddcb9e4180e068"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 550.07it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 589.25it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda26599e0ad47b386580cb393a0f6fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"601abe1b76ba4c1e8cf26501961f7a73"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 681.34it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 666.61it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a82b7a0eaee4959a2822652cee5cc16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd12bd5a05cc4707acd287e3c5a1f2cf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 524.42it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 353.17it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e4786077b7473c99df2aae337b9d01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa5e51f69bf4574a6aaccf8c61b7be4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 308.29it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 501.23it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36cd66495eff46a99f38464ba3af30ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c287ecf9d8814104add81c9468fb7b49"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 321.13it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 515.21it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31c011f6ef84d309cb94adeaa3b1d28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c305a61724924ed3a5432116db6de284"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 402.56it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 536.15it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22a577a49934b17ad374d53b2629d49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29f4b78a6b5455c89dfb6adbda74c77"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 342.76it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 431.51it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779f9472501c4fd58b4e1c104c525976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3e97001151148009927d447736e736e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 566.87it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 455.85it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38d88af03a924381a3939dc1f8b7c257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4ce672feee842fa90496774edc34ff8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 443.14it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 697.66it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c6d3eec78640fb93585cb78533d1be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc7dd284b1649ada10a32d7d17135f2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 530.32it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 285.11it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ce248ce14f47aeab2ee94589a0c63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0356802620d34bd990e268d8abb8c286"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 346.81it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 481.05it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d6f77ddb07241219733c44bedff6a51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e53224a04b64ffcbbbf0e244b862597"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 308.65it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 573.93it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee99b068bff54cc485bd095c45e00946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cfb52eeb728481d8f1782a4b770a0f1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 337.05it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 496.02it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5493cc6a0ce43299aa54db690cf4752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57753fc770dd4722b3edb17ff93a4faf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 258.81it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 515.78it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a7f3e858914e92bf30cd093cd86298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96dcb045f7274ed5b50d16379ecdebe4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 539.46it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 482.99it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a22fac16a647432abccd4c544d5ccddd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b9d4ed43aa49de92d527948a085ee9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 263.89it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 674.11it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bec8f3ea3b8407c9568d42282d00836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dab6fee0bab74ec08cfaa96b9fbc5532"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 471.32it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 648.07it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297e03bc5c38439fa0294667d386e54c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"293367d8d659402e84a3d76570ebf3a9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 513.50it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 517.56it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c065195d834ce38c1e573290a9a474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb6167a1eeeb446bacd6b8ae54fb6618"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 730.97it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 669.80it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60bbbd7fae374c75bb3d98df8a02df68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bce91860073846d097e2e1e0a5c8ad41"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 523.24it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 607.96it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"518ba9413e0444dcb7d6e4b2e3c134a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f162c59c46c24db5829cba1004f149b2"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 258.43it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 630.91it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19bfb86751644da189958fe55597dd5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550d18b66b9244c392b8a02ee2893191"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 486.75it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 710.66it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc26ada7e3c74783b00f7304e0b66145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0911ea1f8b5e4c6aaed894dfe0ef036b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 477.71it/s]\n/opt/conda/lib/python3.7/site-packages/keybert/_model.py:130: UserWarning: Although extracting keywords for multiple documents is faster than iterating over single documents, it requires significantly more memory to hold all word embeddings. Use this at your own discretion!\n  warnings.warn(\"Although extracting keywords for multiple documents is faster \"\n1it [00:00, 449.26it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c631c2aae545aba0037653819f8df2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ee51d5d81b74bfe8c657c4abb18414c"}},"metadata":{}}]},{"cell_type":"code","source":"# print(sim_obj.cosine_similarity())\n# print(sim_obj.euclidian_dist())\n# print(sim_obj.manhatten_dist())\n# print(sim_obj.Jaccard_Similarity()) ","metadata":{"id":"KxBXGf30ojeo","outputId":"88e13e09-3fc8-45f3-9f93-c83d1b4f1b1f","execution":{"iopub.status.busy":"2022-01-11T18:53:42.985527Z","iopub.status.idle":"2022-01-11T18:53:42.986189Z","shell.execute_reply.started":"2022-01-11T18:53:42.985933Z","shell.execute_reply":"2022-01-11T18:53:42.985959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Jaccard_Similarity(standard_answer,student_answer)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:53:42.987463Z","iopub.status.idle":"2022-01-11T18:53:42.988094Z","shell.execute_reply.started":"2022-01-11T18:53:42.987860Z","shell.execute_reply":"2022-01-11T18:53:42.987885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def df_plot(result,stndrd_keyword=candidates_standard,student_keyword=candidates_student):\n#     return pd.DataFrame(result,columns=student_keyword,index=stndrd_keyword)","metadata":{"id":"-YK08fhlgacY","execution":{"iopub.status.busy":"2022-01-11T18:53:42.989542Z","iopub.status.idle":"2022-01-11T18:53:42.990176Z","shell.execute_reply.started":"2022-01-11T18:53:42.989928Z","shell.execute_reply":"2022-01-11T18:53:42.989953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_plot(sim_obj.cosine_similarity())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:53:42.991372Z","iopub.status.idle":"2022-01-11T18:53:42.992172Z","shell.execute_reply.started":"2022-01-11T18:53:42.991849Z","shell.execute_reply":"2022-01-11T18:53:42.991874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_plot(sim_obj.jaccard_distance())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:53:42.993505Z","iopub.status.idle":"2022-01-11T18:53:42.994146Z","shell.execute_reply.started":"2022-01-11T18:53:42.993904Z","shell.execute_reply":"2022-01-11T18:53:42.993928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_plot(sim_obj.euclidian_dist())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:53:42.995391Z","iopub.status.idle":"2022-01-11T18:53:42.996019Z","shell.execute_reply.started":"2022-01-11T18:53:42.995779Z","shell.execute_reply":"2022-01-11T18:53:42.995804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_plot(sim_obj.manhatten_dist())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T18:53:42.997201Z","iopub.status.idle":"2022-01-11T18:53:42.997842Z","shell.execute_reply.started":"2022-01-11T18:53:42.997609Z","shell.execute_reply":"2022-01-11T18:53:42.997633Z"},"trusted":true},"execution_count":null,"outputs":[]}]}